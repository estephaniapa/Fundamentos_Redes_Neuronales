{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QTvkCJPeSge"
   },
   "source": [
    "<script src=\"https://cdn.jsdelivr.net/npm/markdown-toc@0.13.1/dist/gh-md-toc.min.js\"></script>\n",
    "\n",
    "<summary>\n",
    "    <font size=\"10\" color=\"palevioletred\"> Redes neuronales </font>\n",
    "</summary>\n",
    "<summary>\n",
    "    <font size=\"3\" > Proyecto integrador individual </font>\n",
    "</summary>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS6ssHIveSgg"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/mcd.png?raw=true\" alt=\"Image\" style=\"float: right; width: 150px;\">\n",
    "</div>\n",
    "\n",
    "<summary>\n",
    "    <font size=\"5\" color=\"yellowgreen\"> Maestría en Ciencias de Datos </font>\n",
    "</summary>\n",
    "<summary>\n",
    "    <font size=\"5\" color=\"yellowgreen\"> Universidad de Sonora </font>\n",
    "</summary>\n",
    "<br>\n",
    "<summary>\n",
    "    <font size=\"4\"> Propedeutico: Álgebra lineal y optimización </font> \n",
    "</summary>\n",
    "<summary>\n",
    "    <font size=\"4\"> Profesor: Dr. Jesus Francisco Espinoza Fierro </font>\n",
    "</summary>\n",
    "<summary>\n",
    "    <font size=\"4\"> Alumna: Estephania Pivac Alcaraz </font>\n",
    "</summary>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooT_iqu0eSgg"
   },
   "source": [
    "## 1. Definción y ejemplos de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqlaRuzDeSgg"
   },
   "source": [
    "### 1.1 Introducción a las redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sLiPJJFeSgg"
   },
   "source": [
    "<t align=\"justify\">\n",
    "\n",
    "#### **Inteligencia Artificial (AI)**\n",
    "\n",
    "Definir la Inteligencia Artificial es una tarea tan compleja como definir la inteligencia humana. No obstante, en esta introducción, me propongo destacar sus características principales para brindar una comprensión básica de lo que implica la AI.\n",
    "\n",
    "La Inteligencia Artificial, conocida como AI por sus siglas en inglés, se refiere al empleo de computadoras para llevar a cabo tareas que tradicionalmente requieren de la inteligencia humana. Estas tareas abarcan un amplio espectro y pueden incluir capacidades como el cálculo, la memorización de datos, el aprendizaje, la creatividad y la autoconciencia.\n",
    "\n",
    "Podemos entender que la AI se centra en el diseño de programas capaces de tomar decisiones de forma automática en relación con una tarea específica, sin necesitar una programación explícita para decisiones concretas.\n",
    "\n",
    "#### **Aprendizaje Automático (ML)**\n",
    "\n",
    "\n",
    "Dentro del campo de la Inteligencia Artificial, encontramos el área del Aprendizaje Automático (Machine Learning en inglés, abreviado como ML). En esta disciplina, el objetivo principal es permitir que los modelos aprendan de forma autónoma a partir de conjuntos extensos de datos. Se emplean técnicas estadísticas para descubrir patrones en los datos y realizar predicciones sobre nuevos datos sin la necesidad de programar instrucciones explícitas para cada situación.\n",
    "\n",
    "El Aprendizaje Automático se centra en el estudio y la aplicación de algoritmos que analizan datos, aprenden de ellos y, en base a este aprendizaje, generan conclusiones o predicciones para nuevos conjuntos de datos.\n",
    "\n",
    "La diferencia fundamental entre la programación tradicional y el Aprendizaje Automático radica en el enfoque hacia el **aprendizaje a partir de los datos**. En lugar de proporcionar instrucciones específicas para completar una tarea en particular, en el Aprendizaje Automático la máquina se entrena utilizando un conjunto amplio de datos y algoritmos que le permiten aprender cómo realizar dicha tarea sin que se le indique explícitamente cómo hacerlo.\n",
    "\n",
    "**Tipos de aprendizaje**\n",
    "\n",
    "Nuestro cerebro tiene la capacidad de enfrentar diversas situaciones y aprender a manejarlas sin necesidad de instrucciones explícitas. A través de la experiencia, vamos adquiriendo habilidades y mejorando nuestro desempeño.\n",
    "\n",
    "En el campo del Aprendizaje Automático (ML), esta idea se refleja en dos tipos de aprendizaje: el aprendizaje supervisado y el aprendizaje no supervisado.\n",
    "\n",
    "- **Aprendizaje supervisado**\n",
    "\n",
    "El aprendizaje supervisado se basa en la creación de un modelo utilizando datos etiquetados con los valores que se desean predecir. Esto significa que conocemos de antemano las categorías o predicciones correspondientes a cada elemento del conjunto de datos. Durante el proceso de aprendizaje, el modelo utiliza esta información para ajustar sus pesos.\n",
    "\n",
    "Sin embargo, es importante tener en cuenta dos situaciones que debemos evitar. En primer lugar, el overfitting, que ocurre cuando el modelo se ajusta demasiado a los valores de entrada y funciona perfectamente con esos datos, pero no puede realizar predicciones precisas con nuevos datos. Por otro lado, está el underfitting, que sucede cuando el modelo no se entrena lo suficiente con los datos de entrada y carece de la capacidad para realizar predicciones adecuadas. Estas situaciones afectan y limitan la capacidad del modelo para generalizar.\n",
    "\n",
    "- **Aprendizaje no supervisado**\n",
    "\n",
    "En contraste con el aprendizaje supervisado, el aprendizaje no supervisado se enfoca en analizar y agrupar datos que no están etiquetados. Su objetivo principal es descubrir características, patrones y anomalías en los datos.\n",
    "\n",
    "En el aprendizaje no supervisado, el modelo busca identificar estructuras ocultas o grupos naturales dentro de los datos, sin tener información previa sobre las categorías o etiquetas a las que pertenecen. Este enfoque es especialmente útil cuando se trabaja con conjuntos de datos no estructurados o cuando se desconoce la naturaleza subyacente de los datos.\n",
    "\n",
    "#### **Deep Learning (DL)**\n",
    "\n",
    "El Deep Learning es una rama del Aprendizaje Automático (Machine Learning) que se basa en algoritmos inspirados en la estructura y funcionamiento de las redes neuronales del cerebro humano.\n",
    "\n",
    "En el Deep Learning, se utilizan redes neuronales artificiales, que son modelos matemáticos compuestos por capas de unidades interconectadas llamadas neuronas. Estas redes neuronales aprenden a partir de grandes volúmenes de datos, permitiendo que el modelo adquiera la capacidad de reconocer patrones complejos y realizar tareas específicas.\n",
    "\n",
    "A medida que las redes neuronales profundas (deep neural networks) se entrenan con más datos, pueden mejorar su desempeño y generalización. El término \"profundo\" en Deep Learning se refiere a la profundidad de las redes neuronales, es decir, la presencia de múltiples capas ocultas que permiten un procesamiento de la información más complejo y sofisticado.\n",
    "\n",
    "El Deep Learning ha demostrado ser especialmente eficaz en áreas como el reconocimiento de imágenes, el procesamiento de voz y el procesamiento de texto. Su capacidad para extraer características relevantes de los datos y realizar tareas de alta complejidad ha impulsado importantes avances en la Inteligencia Artificial en los últimos años.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfkdN-S9eSgi"
   },
   "source": [
    "#### Neuronas\n",
    "<t align=\"justify\">\n",
    "\n",
    "El cerebro humano está compuesto principalmente por neuronas, células pequeñas que aprenden a emitir señales eléctricas y químicas en función de alguna función.Se estima que hay alrededor de $10^11$ (100 mil millones) de neuronas en el cerebro humano, aproximadamente 15 veces la cantidad total de personas en el mundo. Cada neurona está, en promedio, conectada a otras 10,000 neuronas, lo que da un total de $10^15$ (1 billón) de conexiones entre neuronas.\n",
    "\n",
    "Dado que las neuronas individuales no son capaces de realizar cálculos muy complicados, se cree que la gran cantidad de neuronas y conexiones es lo que le confiere al cerebro su poder computacional. Si bien existen miles de tipos diferentes de neuronas en el cerebro humano, las redes neuronales artificiales (ANN) generalmente intentan replicar solo un tipo para simplificar los cálculos y análisis del modelo.\n",
    "\n",
    "Las neuronas funcionan disparándose cuando reciben suficiente entrada de otras neuronas a las que están conectadas. Por lo general, la función de salida se modela como una función de activación, donde las entradas por debajo de cierto umbral no causan que la neurona se dispare, y las que están por encima del umbral sí lo hacen. Por lo tanto, una neurona muestra lo que se conoce como disparo todo o nada, lo que significa que o está disparando, o está completamente apagada y no produce ninguna salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlxNajPveSgi"
   },
   "source": [
    "### 1.2 Modelo computacional de la neurona\n",
    "<t align=\"justify\">\n",
    "\n",
    "Como se mencionó anteriormente, las neuronas se disparan por encima de un umbral determinado y no hacen nada por debajo de ese umbral, por lo que un modelo de la neurona requiere una función que exhiba las mismas propiedades. La función más simple que cumple con esto es la función escalón.\n",
    "\n",
    "La función escalón se define como:\n",
    "$$\n",
    "H(x) = \\begin{cases} \n",
    "0, & \\text{si } x < \\text{umbral} \\\\\n",
    "1, & \\text{si } x \\geq \\text{umbral} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Donde \"umbral\" es el valor por encima del cual la función toma el valor de 1 y por debajo del cual toma el valor de 0.\n",
    "\n",
    "En este modelo simple de neurona, la entrada es un número que debe superar un umbral de activación para disparar. Sin embargo, las neuronas suelen tener conexiones con múltiples neuronas entrantes, por lo que necesitamos integrar estas entradas en un solo número. Esto se logra mediante una suma ponderada de las entradas, donde cada entrada se multiplica por un peso correspondiente. Si el vector de salidas de las neuronas entrantes se representa como $\\vec{x}$, la suma ponderada se calcula como el producto escalar entre el vector de pesos $\\vec{w}$ y $\\vec{x}$.\n",
    "\n",
    "Para mejorar aún más la capacidad de modelado de la neurona, queremos poder establecer el umbral de activación arbitrariamente. Esto se puede lograr agregando un escalar (que puede ser positivo o negativo) a la suma ponderada de las entradas. Al agregar un escalar de -b, se fuerza el umbral de activación de la neurona a ser b, ya que la nueva función escalón, $H(x+(-b))$, cuando $x=b$, es igual a 0, que es el umbral de la función escalón. El valor $b$ se conoce como sesgo (bias) ya que sesga la función escalón lejos del umbral natural en $x=0$.\n",
    "\n",
    "Entonces, calcular la salida de un modelo neuronal puede resumirse en dos pasos:\n",
    "1. Calculamos la suma ponderada: $\\vec{w}\\cdot \\vec{x} +b$.\n",
    "2. Calculamos la salida: aplicamos la función de activación al resultado del paso 1, y la salida de la neurona es $H(\\vec{w}\\cdot \\vec{x} +b)$, la cual es 1 si $\\vec{w}\\cdot \\vec{x} +b \\ge 0$ y 0 en otro caso.\n",
    "\n",
    "Siguiendo la descripción del paso 2, nuestro modelo de neurona define un clasificador lineal, es decir, una función que divide las entradas en dos regiones con un límite lineal. En dos dimensiones, esto es una línea, mientras que en dimensiones superiores, el límite se conoce como hiperplano.\n",
    "\n",
    "Dado que el cerebro puede calcular más que solo funciones lineales al conectar muchas neuronas entre sí, esto sugiere que al conectar muchos clasificadores lineales juntos se puede obtener una función no lineal. De hecho, se ha demostrado que, para ciertas funciones de activación y un gran número de neuronas, las redes neuronales artificiales pueden modelar cualquier función continua y suave de manera arbitrariamente precisa, resultado conocido como el teorema de aproximación universal.\n",
    "\n",
    "Lamentablemente, dado que la función escalón solo puede producir dos valores diferentes, 0 y 1, una red neuronal artificial compuesta por neuronas con función escalón no puede ser un aproximador universal (en general, las funciones continuas toman más de dos valores). Afortunadamente, existen distintas funciones continuas muy similares a la función escalón que se puede utilizar en aproximadores universales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocIAMXeWeSgi"
   },
   "source": [
    "### 1.3 Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsQD94BseSgi"
   },
   "source": [
    "<t align=\"justify\">\n",
    "\n",
    "Las redes neuronales artificiales (ANN), también conocidas como redes neuronales simuladas (SNN), son modelos computacionales inspirados en el cerebro humano. Están compuestas por un gran número de nodos interconectados, donde cada nodo realiza una operación matemática simple. La salida de cada nodo se determina mediante esta operación y un conjunto de parámetros específicos para ese nodo. Al conectar estos nodos y ajustar cuidadosamente sus parámetros, se pueden aprender y calcular funciones muy complejas.\n",
    "\n",
    "Las redes neuronales artificiales han sido fundamentales en los avances recientes en inteligencia artificial, incluyendo reconocimiento de voz, reconocimiento de imágenes y robótica. Por ejemplo, las ANN pueden realizar reconocimiento de imágenes de dígitos dibujados a mano. Se pueden encontrar ejemplos interactivos en línea.\n",
    "\n",
    "Las redes neuronales artificiales están formadas por capas de nodos que incluyen una capa de entrada, una o más capas ocultas y una capa de salida. Cada nodo, también conocido como neurona artificial, está conectado a otros nodos y posee un peso y un umbral asociados. Si la salida de un nodo individual supera el umbral establecido, el nodo se activa y envía datos a la siguiente capa de la red. En caso contrario, los datos no se transmiten a la siguiente capa.\n",
    "\n",
    "Las redes neuronales de alimentación directa se utilizan principalmente para el aprendizaje supervisado en casos donde los datos a ser aprendidos no son secuenciales ni dependientes del tiempo. Es decir, las redes neuronales de alimentación directa calculan una función $f$ en una entrada de tamaño fijo $x$, de modo que $f(x) ≈ y$ para pares de entrenamiento $(x, y)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zC9alzVeSgj"
   },
   "source": [
    "#### 1.3.1 Perceptrón simple o red neuronal monocapa\n",
    "<t align=\"justify\"> \n",
    "El perceptrón es la red neuronal más básica, también conocida como neurona artificial, consta de un solo nodo con varias entradas y una única salida, sin capas ocultas. \n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/Imagen1.png?raw=true width=600></center>\n",
    "\n",
    "Podemos pensar al perceptrón o la neurona como simples procesadores de información, que tiene múltiples entradas $x_i$, $i=1, 2, \\ldots n$ y una salida $y$. \n",
    "\n",
    "**Componentes de un perceptrón**\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/Imagen2.png?raw=true width=600> </center>\n",
    "\n",
    "1. **Entradas $\\vec{x} \\in \\mathbb{R}^n$:**  Una neurona artificial recibe un vector de entradas numéricas. Corresponden a $\\vec{x} = (x_1, x_2, \\ldots, x_n)$.\n",
    "\n",
    "2. **Pesos $\\vec{w} \\in \\mathbb{R}^n$:** Cada entrada de la neurona tiene asociado un peso $w_i$, que representa la fuerza de la conexión entre la entrada y la neurona. Estos pesos ayudarán a la red neuronal a aprender. Los pesos determinan la contribución relativa de cada entrada en la salida de la neurona. Se pueden inicializar de forma aleatoria y se irán refinando durante el entrenamiento.\n",
    "\n",
    "3. **Bias o sesgo $b \\in \\mathbb{R}$:**  Además de las entradas y los pesos, una neurona puede tener un sesgo (bias) adicional. El sesgo es un parámetro que se suma a la suma ponderada antes de aplicar la función de activación. El sesgo permite ajustar el punto de activación de la neurona y controlar el umbral de activación.\n",
    "\n",
    "4. **Procesamiento lineal**\n",
    "Las entradas y los pesos se multiplican y suman, para calcular la suma ponderada de las entradas. Esta suma ponderada es una combinación lineal de las entradas y los pesos, y se le agrega el bias.\n",
    "$$z = \\vec{w}\\cdot \\vec{x} +b= \\sum_{i=1}^n x_i w_i + b$$\n",
    "\n",
    "\n",
    "\n",
    "4. **Función de activación $f$:**  \n",
    "La función de activación es una función matemática que activa los pesos de una neurona en base al resultado de la computación de esa neurona.\n",
    "La suma ponderada obtenida del procesamiento lineal se pasa a través de una función de activación, que introduce no linealidad en la salida de la neurona. Esta determina el rango y la forma de la salida de la neurona.  Las funciones de activación son esenciales en las redes neuronales para introducir no linealidad y permitir el aprendizaje de relaciones complejas en los datos. Permiten una mayor representación y expresividad, y son fundamentales para el éxito y la eficacia de las redes neuronales en una amplia gama de aplicaciones.\n",
    "$$f(z) = f(\\vec{w}\\cdot \\vec{x} +b)$$\n",
    "\n",
    "5. **Salida $y$:** La salida de la neurona artificial, la variable dependiente $y$, se calcula aplicando la función de activación a la suma ponderada más el sesgo. La salida puede ser la salida final de la neurona o puede ser la entrada para otras neuronas en una red neuronal más grande.\n",
    "\n",
    "En general, un perceptrón con función de activación $f(x)$ tiene salida $$a = f(\\vec{w}\\cdot \\vec{x} +b)$$ \n",
    "\n",
    "Para que un perceptrón aprenda a clasificar correctamente un conjunto de pares de entrada-salida (x, y), debe ajustar los pesos $w$ y el sesgo $b$ para aprender una buena clasificación. Si el perceptrón utiliza una función de activación distinta a la función escalón (por ejemplo, la función sigmoide), entonces los pesos y el sesgo deben ajustarse para que la salida o se acerque a la etiqueta verdadera $y$.\n",
    "\n",
    "#### Función de error \n",
    "\n",
    "El proceso de aprendizaje requiere de una función de error o pérdida que cuantifique la diferencia entre las salidas del perceptrón $a$ y los valores reales $y$ para una entrada $x_i$ para todo el conjunto de pares $(\\vec{x}, y)$. Una función de pérdida típica es el *Error Cuadrado Medio (MSE)* definido para un conjunto de pares $(\\vec{x},y)$ de tamaño $N$, $X = \\{ (\\vec{x}_1,y_1), (\\vec{x}_2,y_2), \\ldots, (\\vec{x}_N,y_N) \\}$ de la siguiente manera:\n",
    "$$MSE(X) = \\frac{1}{2N} \\sum_{i=1}^N (a_i-y_i)^2 = \\frac{1}{2N} \\sum_{i=1}^N (f(\\vec{w}\\cdot \\vec{x} +b)-y_i)^2$$\n",
    "\n",
    "Donde $a_i$ denota la salida del perceptrón en la entrada $x_i$ con la función de activación $f$. El factor de $\\frac{1}{2}$ se incluye para simplificar el cálculo de la derivada más adelante. El objetivo es encontrar los valores de $\\vec{w}$ y $b$ tales que minimicen el MSE.\n",
    "\n",
    "### Descenso de gradiente\n",
    "\n",
    "Dado que la función de error $Loss(X,θ)$, donde $\\theta$ denota el conjunto de pesos $\\vec{w}$ y sesgos $b$, define una función bastante compleja (es una función de la salida de la ANN, que es una composición de muchas funciones no lineales), encontrar el mínimo analíticamente es generalmente imposible. Afortunadamente, existe un método general para minimizar funciones diferenciables llamado *descenso de gradiente*. Básicamente, el descenso de gradiente encuentra el gradiente de una función $f$ en un valor particular $x$ (en el caso de una ANN, esos valores serán los parámetros $θ$) y luego actualiza ese valor moviéndose en la dirección del negativo del gradiente. En general (depende del tamaño del paso $\\eta$), esto encontrará un valor cercano $$x' = x - \\eta ∇f(x)$$ para el cual $f(x') < f(x)$. Este proceso se repite hasta encontrar un mínimo local o hasta que el gradiente converja lo suficiente (es decir, se vuelva más pequeño que un umbral determinado). El aprendizaje para una ANN generalmente comienza con una inicialización aleatoria de los parámetros (los vectores de peso y los sesgos), seguida de actualizaciones sucesivas de esos parámetros basadas en el descenso de gradiente hasta que la función de error $Loss(X,θ)$ converja.\n",
    "\n",
    "Una característica importante es que los parámetros no se resuelven en un solo cálculo, sino que se mejoran gradualmente moviéndose en la dirección del gradiente negativo. Por lo tanto, si los pares de entrada-salida llegan de manera secuencial, la ANN puede realizar el descenso de gradiente en un par de entrada-salida durante un cierto número de pasos y luego hacer lo mismo una vez que llegue el siguiente par de entrada-salida. Con una elección adecuada del tamaño del paso $\\eta$, este enfoque puede producir resultados similares al descenso de gradiente en todo el conjunto de datos X (conocido como aprendizaje por lotes).\n",
    "\n",
    "Debido a que el descenso de gradiente es un método local (la dirección del paso está determinada por el gradiente en un solo punto), solo puede encontrar mínimos locales. Si bien esto generalmente es un problema importante en la mayoría de las aplicaciones de optimización, investigaciones recientes han sugerido que encontrar mínimos locales no es realmente un problema para las ANNs, ya que la gran mayoría de los mínimos locales están distribuidos de manera uniforme y tienen magnitudes similares para ANNs grandes.\n",
    "\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "Durante mucho tiempo, se consideró que el cálculo del gradiente para las redes neuronales artificiales (ANN) era matemáticamente intratable debido a su estructura con un gran número de nodos y capas, lo cual generaba una función de error altamente no lineal. Sin embargo, a mediados de la década de 1980, los científicos de la computación lograron desarrollar un método para calcular el gradiente con respecto a los parámetros de una ANN, conocido como retropropagación o \"retropropagación por errores\". El descubrimiento de este método marcó un hito en la investigación de las redes neuronales artificiales, ya que finalmente se volvió factible entrenar ANN complejas y resolver problemas de aprendizaje no triviales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6GY7P63eSgj"
   },
   "source": [
    "#### 1.3.2 Componentes de una red neuronal\n",
    "\n",
    "Una red neuronal consiste en un largo número de unidades simples llamadas neuronas, que reciben y transmiten señales unas con otras. Es decir, consisten de capas de neuronas, y las redes neuronales artificiales multi-capas pueden resolver problemas no linealmente separables.\n",
    "\n",
    "A menudo las arquitecturas de redes neuronales están compuestas por capas de neuronas que se comunican entre sí, principalmente las podemos dividir en:\n",
    "\n",
    "1. **Capa de entrada:** Es la capa inicial de la red neuronal donde se introducen los datos de entrada. Cada neurona en esta capa representa una característica o variable de entrada. No hay cálculos o transformaciones en esta capa, solo se transmiten las entradas a la siguiente capa.\n",
    "\n",
    "2. **Capas ocultas:** Son capas intermedias entre la capa de entrada y la capa de salida. Estas capas realizan cálculos y transformaciones complejas para procesar la información de entrada. Pueden haber una o varias capas ocultas en una red neuronal, y el número de neuronas en cada capa oculta puede variar.\n",
    "\n",
    "3. **Capa de salida:** Es la capa final de la red neuronal donde se obtienen las salidas predichas. La forma y el número de neuronas en esta capa dependen del problema que se esté abordando. Por ejemplo, en problemas de clasificación binaria, se puede utilizar una neurona con una función de activación sigmoide para producir una salida entre 0 y 1. En problemas de clasificación multiclase, se puede utilizar una neurona por clase con una función de activación softmax.\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/Imagen6.png?raw=true width=500> </center>\n",
    "\n",
    "La capa de entrada es donde el modelo ingiere los datos para posteriormente transformarlos en las capas ocultas y la capa final es donde se realiza la predicción o clasificación final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAJQnispeSgj"
   },
   "source": [
    "#### 1.2.3 Ejemplos de arquitecturas de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVVoUvOEeSgk"
   },
   "source": [
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/image7.png?raw=true width=600> </center>\n",
    "<t align=\"justify\">\n",
    "Existen varias arquitecturas de redes neuronales, cada una diseñada para abordar diferentes tipos de problemas y aprender patrones específicos en los datos. A continuación, se presentan algunas de las arquitecturas más comunes de redes neuronales:\n",
    "\n",
    "**Redes Neuronales Feedforward (FFNN)**\n",
    "\n",
    "Una red neuronal feedforward, también conocida como red neuronal de propagación hacia adelante, es un tipo de red neuronal artificial que se utiliza en la mayoría de las aplicaciones de aprendizaje automático y reconocimiento de patrones. Es una red neuronal en la que la información fluye en una sola dirección, desde la entrada hasta la salida, sin bucles ni conexiones hacia atrás.\n",
    "\n",
    "La red neuronal feedforward consta de múltiples capas:\n",
    "- una capa de entrada\n",
    "- una o más capas ocultas\n",
    "- una capa de salida\n",
    "\n",
    "Cada capa consta de un conjunto de nodos o neuronas, que reciben entradas de la capa anterior y generan salidas para la capa siguiente. Los pesos entre los nodos se ajustan durante el entrenamiento de la red neuronal para minimizar el error en la predicción de la salida.\n",
    "\n",
    "El proceso de predicción en una red neuronal feedforward implica alimentar los datos de entrada a través de la capa de entrada y las capas ocultas, y finalmente producir una salida en la capa de salida. Cada capa de la red neuronal utiliza una función de activación no lineal para transformar las entradas y generar las salidas correspondientes. Las funciones de activación más comunes son la función sigmoidal y la función ReLU.\n",
    "\n",
    "Las redes neuronales feedforward son utilizadas en una amplia variedad de aplicaciones de aprendizaje automático, incluyendo la clasificación de imágenes, el procesamiento del lenguaje natural, el reconocimiento de voz, la detección de fraudes, la predicción de series temporales, entre otros.\n",
    "\n",
    "\n",
    "##### Redes Neuronales Recurrentes (RNN)\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/image8.jpeg?raw=true width=600> </center>\n",
    "\n",
    "Una red neuronal recurrente (RNN) es un tipo de red neuronal artificial que utiliza datos secuenciales o datos de series de tiempo. Estos algoritmos de aprendizaje profundo se utilizan comúnmente para problemas ordinales o temporales, como la traducción de idiomas, el reconocimiento de voz y subtítulos de imágenes.\n",
    "\n",
    "Cabe mencionar que están incorporados en aplicaciones populares como Siri, búsqueda por voz y Google Translate.\n",
    "Al igual que las redes neuronales feedforward y convolucionales (CNN), las redes neuronales recurrentes utilizan datos de entrenamiento para aprender. Se distinguen por su \"memoria\", ya que toman información de entradas anteriores para utilizarse en los datos de entrada y en los resultados.\n",
    "\n",
    "Si bien las redes neuronales profundas tradicionales asumen que los datos de entrada y los resultados son independientes entre sí, los resultados de las redes neuronales recurrentes depende de los elementos anteriores dentro de la secuencia. Aunque los eventos futuros también serían útiles para determinar los resultados de una secuencia dada, las redes neuronales recurrentes unidireccionales no pueden tener en cuenta estos eventos en sus predicciones.\n",
    "\n",
    "\n",
    "##### Redes Neuronales Convolucionales (CNN)\n",
    "\n",
    "Las redes neuronales convolucionales pueden tener decenas o cientos de capas, y cada una de ellas aprende a detectar diferentes características de una imagen. Se aplican filtros a las imágenes de entrenamiento con distintas resoluciones, y la salida resultante de convolucionar cada imagen se emplea como entrada para la siguiente capa. Los filtros pueden comenzar como características muy simples, tales como brillo y bordes, e ir creciendo en complejidad hasta convertirse en características que definen el objeto de forma singular.\n",
    "\n",
    "Una CNN consta de una capa de entrada, una capa de salida y varias capas ocultas entre ambas.\n",
    "Estas capas realizan operaciones que modifican los datos, con el propósito de comprender sus características particulares.\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/image12.png?raw=true width=600> </center>\n",
    "\n",
    "- Capa de entrada: La capa de entrada recibe la imagen de entrada y puede aplicar algunas transformaciones iniciales, como redimensionar la imagen o normalizar los valores de píxeles.\n",
    "\n",
    "- Capas convolucionales: Las capas convolucionales son el componente principal de una CNN y se utilizan para extraer características de las imágenes. Cada capa convolucional aplica múltiples filtros (kernels) que se deslizan por la imagen y realizan operaciones de convolución para detectar características locales, como bordes, texturas o formas. Estas capas convolucionales generan mapas de características convolucionales, que capturan información relevante de la imagen a diferentes niveles de abstracción.\n",
    "\n",
    "- Capas de activación: Después de cada capa convolucional, se aplica una función de activación no lineal, como la función ReLU (Rectified Linear Unit), para introducir no linearidades en la red y permitir la representación de relaciones no lineales en los datos.\n",
    "\n",
    "- Capas de agrupación (Pooling): Las capas de agrupación se utilizan para reducir la dimensionalidad de los mapas de características y hacer que la red sea más robusta ante pequeñas variaciones en la posición de las características detectadas.\n",
    "La operación de agrupación toma una región de los mapas de características y aplica una función de agregación, como el máximo o el promedio, para obtener un único valor representativo de esa región.\n",
    "\n",
    "- Capas totalmente conectadas: Después de las capas convolucionales y de agrupación, se pueden agregar una o varias capas totalmente conectadas, similares a las de una red neuronal tradicional. Estas capas toman los mapas de características resultantes y los \"aplanan\" en un vector unidimensional, que luego se alimenta a través de capas densamente conectadas. Estas capas completamente conectadas aprenden a combinar y clasificar las características extraídas por las capas anteriores para producir las salidas deseadas, como etiquetas de clase en un problema de clasificación.\n",
    "\n",
    "- Capa de salida: La capa de salida generalmente consiste en una o varias neuronas que representan las clases o valores de salida deseados. En problemas de clasificación, se utiliza una función de activación softmax para obtener una distribución de probabilidades sobre las clases. En problemas de regresión, se puede utilizar una función de activación lineal o una función no lineal adecuada, según el rango de valores de salida requerido.\n",
    "\n",
    "\n",
    "Cabe mencionar que la estructura exacta de una red neuronal convolucional puede variar dependiendo de la arquitectura específica utilizada, como LeNet, AlexNet, VGGNet, ResNet, entre otras. Cada arquitectura puede tener una cantidad diferente de capas, así como también puede incluir capas adicionales o técnicas avanzadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M_jpIA9eSgk"
   },
   "source": [
    "## 2. Esquema matemático que involucran las redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdOvDM-ReSgk"
   },
   "source": [
    "<t align=\"justify\">\n",
    "\n",
    "Para realizar el esquema matemático vamos a considerar el perceptrón multicapa (MLP) que es una red neuronal artificial compuesta por múltiples perceptrones. A diferencia de los perceptrones de una sola capa, los MLP son capaces de aprender y calcular funciones no linealmente separables. Debido a su capacidad de aprender funciones no lineales, son una de las técnicas principales de aprendizaje automático tanto para la regresión como para la clasificación en el aprendizaje supervisado.\n",
    "\n",
    "Los MLP generalmente se organizan en lo que se conoce como capas. Como se mencionó anteriormente, la red neuronal artificial generalizada consta de una capa de entrada, algún número (posiblemente cero) de capas ocultas y una capa de salida. \n",
    "\n",
    "**Definiciones**\n",
    "\n",
    "Enseguida se define un MLP típico de $m$ capas (lo que significa que se compone de $m-2$ capas ocultas) que calcula una salida unidimensional $a$ en una entrada $n$-dimensional $x = (x_1, ..., x_n)$.\n",
    "\n",
    "Supongamos que:\n",
    "- El perceptrón de salida tiene una función de activación $f_o$, mientras que los perceptrones de las capas ocultas tienen funciones de activación $f$.\n",
    "\n",
    "- Todo perceptrón en la capa $l_i$ está conectado con cada perceptrón en la capa $l_{i-1}$, esto es, las capas estan *completamente conectadas*. Por lo tanto, cada perceptrón depende de las salidas de todos los perceptrones en la capa anterior (podemos suponer esto sin pérdida de generalidad, ya que el peso que conecta dos perceptrones aún puede ser cero, lo cual es equivalente a no tener conexión presente).\n",
    "\n",
    "- No hay conexiones entre los perceptrones dentro de la misma capa.\n",
    "\n",
    "Utilizaremos la siguiente notación:\n",
    "- $w_{ij}^k$: es el peso del perceptrón $j$ en la capa $l_k$ hacia el siguiente nodo $i$ en la capa $l_{k-1}$.\n",
    "- $b_i^k$: sesgo para el perceptrón $i$ en la capa $l_k$\n",
    "- $z_i^k$: suma con pesos más el sesgo en el nodo $i$ en la capa $l_k$.\n",
    "- $a_i^k$: salida del nodo $i$ en la capa $l_k$.\n",
    "- $r_k$: número de nodos en la capa $l_k$.\n",
    "- $\\vec{w}_i^k$: vector de pesos para el perceptrón $i$ en la capa $l_k$, i.e. $\\vec{w}_i^k=(w_{1i}^k, \\ldots, w_{r_k i}^k)$.\n",
    "- $\\vec{a}^k$: vector de salidas para la capa $l_k$, es decir, $\\vec{a}=(a_1^k, a_2^k, \\ldots, a_{r_k}^k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsHqN36CeSgk"
   },
   "source": [
    "### 2.1 Entrenamiento de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvT0H-FWeSgk"
   },
   "source": [
    "<t align=\"justify\">\n",
    "El objetivo del algoritmo de entrenamiento de redes neuronales es ajustar los pesos sinápticos y los sesgos de la red de manera que la red pueda aprender y generalizar a partir de los datos de entrenamiento. El algoritmo busca encontrar una configuración de pesos y sesgos que minimice la diferencia entre las salidas predichas por la red y las salidas objetivo deseadas.\n",
    "\n",
    "El proceso de entrenamiento implica presentar iterativamente los ejemplos de entrenamiento a la red neuronal, propagar hacia adelante las entradas a través de las capas de la red para calcular las salidas predichas y luego comparar esas salidas con las salidas objetivo. A partir de la diferencia entre las salidas predichas y las salidas objetivo, se calcula una función de pérdida o error que cuantifica qué tan bien está realizando la red en la tarea.\n",
    "\n",
    "El algoritmo de entrenamiento utiliza el error calculado para ajustar los pesos y sesgos en sentido contrario al gradiente de la función de pérdida. Esto se conoce como descenso de gradiente y se realiza mediante el algoritmo de backpropagation. El objetivo es encontrar una configuración de pesos y sesgos que minimice el error de manera gradual a medida que se presentan más ejemplos de entrenamiento.\n",
    "\n",
    "En resumen, el objetivo del algoritmo de entrenamiento de redes neuronales es optimizar los parámetros de la red para que pueda realizar predicciones precisas y generalizar a partir de los datos de entrenamiento, es decir, ser capaz de realizar predicciones precisas en datos no vistos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAibi_l_eSgk"
   },
   "source": [
    "#### 2.1.1 Forward propagation\n",
    "<t align=\"justify\">\n",
    "El forward propagation, también conocido como propagación hacia adelante, es el proceso mediante el cual se calculan las salidas de una red neuronal multicapa (MLP) para un conjunto de datos de entrada dado. Durante este proceso, la información se propaga desde la capa de entrada hasta la capa de salida de la red neuronal, pasando a través de las capas ocultas intermedias. Cada neurona en una capa determinada toma como entrada las salidas de las neuronas de la capa anterior, realiza una combinación lineal ponderada de esas entradas utilizando sus pesos correspondientes y aplica una función de activación no lineal para producir su salida. Este cálculo se realiza sucesivamente para todas las capas hasta llegar a la capa de salida, donde se obtiene la salida final del MLP.\n",
    "\n",
    "Calcular la salida $a$ de la MLP implica seguir el siguiente esquema:\n",
    "1. Inicializar la capa de entrada $l_0$. Tomamos los valores de salida $a_i^0$ de los nodos en la capa de entrada $l_0$ como la entrada correspondiente asociada del vector de entradas $\\vec{x}=(x_1, x_2, \\ldots, x_n)$, i.e., $$a_i^0 = x_i$$\n",
    "\n",
    "2. Calculamos la suma con pesos y las salidas de cada capa oculta en orden desde $l_1$ hasta $l_{m-1}$. Para $k$ desde $1$ hasta $m-1$,\n",
    "    \n",
    "a. Calculamos: $$z_i^k=\\vec{w}_i^k \\cdot \\vec{a}^{k-1} + b_i^k, \\ \\ \\ \\ \\mbox{para }i=1,\\ldots, r_k.$$\n",
    "    \n",
    "b. Calculamos las salidas.\n",
    "$$a_i^k=g(z_i^k), \\ \\ \\ \\ \\mbox{para }i=1,\\ldots, r_k.$$\n",
    "\n",
    "3. Calculamos la salida $y$ de la capa de salida $l_m$.\n",
    "\n",
    "a. Calculamos $$h_1^m = \\vec{w}_1^m \\cdot \\vec{a}^{m-1}+b_1^m = b_1^m \\sum_{j=1}^{r_{m-1}} w_{ji}^ka_j^{k-1}$$.\n",
    "\n",
    "b. Calculamos $$a = a_1^m = g_o(z_1^m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uym3-9-JeSgl"
   },
   "source": [
    "#### 2.1.2 Función de pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIbpF1x4eSgl"
   },
   "source": [
    "<t align=\"justify\">\n",
    "\n",
    "Es importante establecer cómo vamos a medir el desempeño de la red neuronal, para esto necesitamos definir cómo mediremos los errores. La función de pérdida es una parte fundamental cuando utilizamos modelos de redes neuronales porque determina el objetivo del algoritmo.\n",
    "$$Loss(\\hat{y}_{i}, y_{i})$$\n",
    "\n",
    "La \"loss function\" (función de pérdida) en las redes neuronales es una función que cuantifica el error entre las salidas predichas por la red y las salidas objetivo o etiquetas conocidas. El objetivo del entrenamiento es minimizar la función de pérdida promedio, es decir, reducir la discrepancia entre las salidas predichas y las salidas objetivo.\n",
    "\n",
    "$$AverageLoss\\Big (\\frac{1}{n} \\sum_{i=1}^n Loss( \\hat{y}_{i}, y_{i})\\Big)$$\n",
    "\n",
    "Existen diferentes funciones de pérdida, algunos ejemplos comunes son las siguientes:\n",
    "\n",
    "- Error cuadrado medio (MSE): Pone gran énfasis la magnitud promedio del error, independientemente de su dirección. Sin embargo, debido al cuadrado, las predicciones que están lejos de los valores reales son penalizadas en gran medida en comparación con las predicciones menos desviadas. Además, el MSE tiene propiedades matemáticas favorables que facilitan el cálculo de los gradientes. $$MSE = \\frac{ \\sum_{i=1}^n ( y_{i} - \\hat{y}_{i})^2}{n}$$\n",
    "\n",
    "- Error absoluto medio (MAE): El error absoluto medio (MAE, por sus siglas en inglés), por otro lado, se mide como el promedio de la suma de las diferencias absolutas entre las predicciones y las observaciones reales. Al igual que el error cuadrático medio (MSE), esto también mide la magnitud del error sin tener en cuenta su dirección. A diferencia del MSE, el MAE requiere herramientas más complicadas, como la programación lineal, para calcular los gradientes. Además, el MAE es más robusto ante valores atípicos ya que no utiliza el cuadrado $$MAE = \\frac{ \\sum_{i=1}^n | y_{i} - \\hat{y}_{i}|}{n}$$\n",
    "\n",
    "- Cross Entropy (CE): La entropía cruzada se utiliza comúnmente en problemas de clasificación, especialmente cuando se trabaja con modelos que generan probabilidades. Existen diferentes variantes de la entropía cruzada, como la entropía cruzada binaria y la entropía cruzada categórica.\n",
    "$$\n",
    "CE = - Y \\cdot \\log(\\hat{Y}) + (1 - Y) \\cdot \\log(1 - \\hat{Y})\n",
    "$$\n",
    "\n",
    "- Categorical Cross Entropy (CCE): Esta función mide la discrepancia entre la distribución de probabilidad predicha por la red y la distribución de probabilidad verdadera. \n",
    "$$\n",
    "CCE = - \\sum_{i} Y_i \\cdot log(\\hat{Y}_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iGgTvgXeSgl"
   },
   "source": [
    "#### 2.1.3 Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K9tWTN0eSgl"
   },
   "source": [
    "<t align=\"justify\">\n",
    "Backpropagation requiere tres elementos:\n",
    "1. El conjunto de parejas entrada-salida $(\\vec{x}_i, \\vec{y}_i)$, donde $\\vec{x}_i$ es la entrada y $\\vec{y}_i$ es la salida deseada de la red para la entrada $\\vec{x}_i$. El conjunto de parejas entrada-salida de tamaño $N$ se denota por $X=\\{(\\vec{x}_1,\\vec{y}_1), \\ldots, (\\vec{x}_N, \\vec{y}_N) \\}$.\n",
    "\n",
    "2. Una red neuronal feedforward, cuyos parámetros se denotan colectivamente como $\\theta$. En backpropagation, los principales parámetros de interés son $w_{ij}^k$, los pesos entre el nodo $j$ en la capa $l_k$ y el nodo $i$ en la capa $l_{k-1}$, y $b_i^k$, el sesgo para el nodo $i$ en la capa $l_k$. No existe conexión entre nodos de la misma capa y las capas estan completamente conectadas.\n",
    "\n",
    "3. Una función de error $J(X, \\theta)$, que define el error entre la salida deseada $y_i$ y la salida calculada $\\hat{y}_i$ de la red neuronal en la entrada $x_i$ para un conjunto de pares entrada-salida $(x_i, y_i)$ en $X$ y un valor particular de los parámetros $θ$. \n",
    "\n",
    "Entrenar una red neuronal con descenso de gradiente requiere el cálculo del gradiente de la función de error $J(X,θ)$ con respecto a los pesos $w_{ij}^k$ y los sesgos $b_i^k$. Luego, de acuerdo con la tasa de aprendizaje $\\alpha$, en cada iteración del descenso de gradiente se actualizan los pesos y sesgos (denotados colectivamente como $θ$) de la siguiente manera:\n",
    "$$\\theta^{t+1}=\\theta^t - \\alpha \\frac{\\partial J(X, \\theta^t)}{\\partial \\theta}$$\n",
    "\n",
    "donde $θ^t$ denota los parámetros de la red neuronal en la iteración t del descenso del gradiente.\n",
    "\n",
    "Además, $\\alpha$ representa la tasa de aprendizaje del algoritmo. La tasa de aprendizaje, también conocida como tasa de paso o learning rate en inglés, es un hiperparámetro crítico en el algoritmo de descenso de gradiente utilizado en el entrenamiento de redes neuronales y otros algoritmos de optimización.\n",
    "\n",
    "En el contexto del descenso de gradiente, la tasa de aprendizaje determina el tamaño de los pasos que se dan para ajustar los pesos y sesgos de la red neuronal en dirección al mínimo de la función de pérdida. Es decir, indica cuánto se actualizan los parámetros en cada iteración del algoritmo.\n",
    "\n",
    "Una tasa de aprendizaje alta puede permitir un aprendizaje más rápido, ya que los parámetros se actualizan en grandes pasos. Sin embargo, si la tasa de aprendizaje es demasiado alta, existe el riesgo de que el algoritmo no converja hacia el mínimo global y pueda oscilar o divergir.\n",
    "\n",
    "Seleccionar una tasa de aprendizaje adecuada es crucial para el rendimiento de la red neuronal. Si la tasa de aprendizaje es demasiado alta, el algoritmo puede oscilar o no converger. Si la tasa de aprendizaje es demasiado baja, el algoritmo puede llevar mucho tiempo en converger o quedar atrapado en mínimos locales subóptimos. En la práctica, la selección de la tasa de aprendizaje es un proceso de prueba y error.\n",
    "\n",
    "\n",
    "<center><img src='https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/learning_rate.png?raw=true' width=600> </center>\n",
    "\n",
    "**¿Cuál es el objetivo?**\n",
    "\n",
    "Como se mencionó anteriormente, uno de los desafíos principales en el entrenamiento de redes neuronales de alimentación hacia adelante con múltiples capas es determinar cómo aprender representaciones internas efectivas, es decir, qué pesos y sesgos deben tener los nodos de las capas ocultas. A diferencia del perceptrón, los nodos de las capas ocultas no tienen una salida objetivo directa, ya que se utilizan como pasos intermedios en el cálculo.\n",
    "\n",
    "Dado que los nodos de las capas ocultas no tienen una salida objetivo específica, no se puede definir una función de error única para esos nodos. En cambio, cualquier función de error para un nodo en particular dependerá de los valores de los parámetros en las capas anteriores (ya que esas capas determinan la entrada del nodo) y de las capas posteriores (ya que la salida del nodo afectará el cálculo de la función de error $J(X,θ)$). Esta interdependencia de los parámetros entre capas puede complicar las matemáticas involucradas (especialmente debido al uso de la regla del producto, que se discutirá a continuación) y, si no se implementa correctamente, puede resultar en cálculos lentos en el descenso del gradiente. Para abordar estas dificultades, se utiliza un algoritmo llamado retropropagación (backpropagation), que simplifica las matemáticas del descenso del gradiente y permite su cálculo eficiente.\n",
    "\n",
    "\n",
    "#### 2.1.4  Descenso de gradiente: Tipos y variaciones\n",
    "\n",
    "Hay tres tipos de  algoritmos de aprendizaje de descenso de gradiente: descenso de gradiente por lotes, descenso de gradiente estocástico y descenso de gradiente por mini lotes.\n",
    "\n",
    "**Descenso de gradiente por lote** \n",
    " \n",
    "El descenso de gradiente por Lote  suma el error para cada punto en un conjunto de entrenamiento, actualizando el modelo solo después de que todos los ejemplos de entrenamiento  han sido evaluados. Este proceso se conoce como época de entrenamiento.\n",
    "\n",
    "Si bien este procesamiento por lotes proporciona eficiencia de cálculo, aún puede tener un tiempo de procesamiento prolongado para grandes conjuntos de datos de entrenamiento, ya que aún necesita almacenar todos los datos en la memoria. El descenso del gradiente por lotes también suele producir un gradiente de error estable y una convergencia, pero a veces ese punto de convergencia no es el ideal, encontrando el mínimo local versus el global.\n",
    "\n",
    "**Descenso de gradiente estocástico**\n",
    " \n",
    "El descenso de gradiente estocástico (SGD) ejecuta una época de entrenamiento para cada ejemplo dentro del conjunto de datos y actualiza cada  parámetro del ejemplo de entrenamiento, uno a la vez. Dado que solo necesita guardar un ejemplo de entrenamiento, es más fácil almacenarlos en la memoria. Si bien estas actualizaciones frecuentes pueden ofrecer más detalles y velocidad, pueden resultar en pérdidas en la eficiencia computacional en comparación con el descenso de gradiente de lote . Sus actualizaciones frecuentes pueden resultar en gradientes ruidosos, pero esto también puede ser útil para escapar del mínimo local y encontrar el global.\n",
    "\n",
    "**Descenso de gradiente de mini-lote**\n",
    "\n",
    "El descenso de gradiente de Mini-lote combina conceptos tanto del descenso de gradiente por lotes como del descenso de gradiente estocástico. Divide el conjunto de datos de entrenamiento en pequeños tamaños de lote  y realiza actualizaciones en cada uno de esos lotes. Este enfoque logra un equilibrio entre la eficiencia computacional del lote de descenso de gradiente y la velocidad del  descenso de gradiente estocástico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQf158UHeSgl"
   },
   "source": [
    "## 3. Propuesta de Proyecto: Red Neuronal Feedforward de Dos Capas para Predicción de Admisión en un Posgrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzeBVwgSeSgl"
   },
   "source": [
    "### 3.1 Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlntFPEHeSgm"
   },
   "source": [
    "<t align=\"justify\">\n",
    "\n",
    "**Problema:**\n",
    "El problema que se aborda en este proyecto es el proceso de admisión en programas de posgrado, el cual es altamente competitivo y complejo. El objetivo es mejorar la eficiencia y precisión de este proceso.\n",
    "\n",
    "**Objetivo:**\n",
    "El objetivo principal de este proyecto es desarrollar una red neuronal feedforward de dos capas con función de pérdida MSE (Mean Squared Error). Esta red estará diseñada para utilizar datos que contienen características relevantes de los alumnos y predecir la probabilidad con la que serán aceptados en un programa de posgrado.\n",
    "\n",
    "**Variables utilizadas:**\n",
    "Las variables utilizadas en este proyecto incluyen:\n",
    "\n",
    "- Puntajes de GRE y TOEFL: Se utilizarán los puntajes obtenidos en los exámenes estandarizados GRE y TOEFL como indicadores del rendimiento académico de los solicitantes.\n",
    "\n",
    "- Calificación de la universidad de origen: Se considerará la reputación y el prestigio de la universidad de la cual proviene el solicitante como un factor influyente en su probabilidad de ser aceptado en el programa de posgrado.\n",
    "\n",
    "- Fortaleza de la declaración de propósito (SOP): La calidad y coherencia de la declaración de propósito presentada por el solicitante será evaluada como una medida de su interés y compromiso con el programa de posgrado.\n",
    "\n",
    "- Cartas de recomendación (LOR): Se tendrán en cuenta las cartas de recomendación proporcionadas por profesores u otras personas de autoridad académica, las cuales darán testimonio de las habilidades y aptitudes del solicitante.\n",
    "\n",
    "- GPA de pregrado (CGPA): El promedio de calificaciones obtenido durante la carrera universitaria será utilizado como un indicador de desempeño académico previo del solicitante.\n",
    "\n",
    "- Experiencia en investigación: La experiencia en investigación que haya tenido el solicitante se considerará como un factor relevante en su probabilidad de ser aceptado en el programa de posgrado.\n",
    "\n",
    "En resumen, el objetivo es utilizar una red neuronal para analizar estas variables relevantes de los solicitantes y predecir la probabilidad de aceptación en un programa de posgrado, lo que permitiría mejorar la eficiencia y precisión del proceso de admisión.\n",
    "\n",
    "Los datos fueron obtenidos de [Kaggle](https://www.kaggle.com/datasets/mukeshmanral/graduates-admission-prediction).\n",
    "\n",
    "\n",
    "### 3.2 **Red neuronal propuesta:**\n",
    "\n",
    "En este proyecto, se propone el desarrollo de una red neuronal para mejorar la eficiencia y precisión del proceso de admisión en programas de posgrado. La red neuronal implementada constará de una capa de entrada, dos capas densas ocultas y una capa de salida. A continuación, se describe en detalle la configuración de la red:\n",
    "\n",
    "Capa de entrada: La capa de entrada está compuesta por 7 neuronas, representando las 7 variables numéricas relevantes para la predicción de la probabilidad de admisión en el programa de posgrado $X=(x_1, x_2, x_3, x_4, x_5, x_6, x_7)$. Estas variables incluyen puntajes de exámenes estandarizados, calificaciones universitarias y otras métricas importantes.\n",
    "\n",
    "Capas densas ocultas: La red neuronal consta de dos capas densas ocultas, cada una con 7 neuronas. Estas capas están completamente conectadas, lo que significa que cada neurona en una capa está conectada a todas las neuronas en la capa siguiente. La función de activación utilizada en estas capas es la función relu (Rectified Linear Unit), que introduce no linealidad en la red y ayuda a capturar relaciones complejas entre las variables de entrada.\n",
    "\n",
    "Capa de salida: La capa de salida consta de una sola neurona que representa el valor de salida $y$. Esta salida corresponde a la probabilidad de ser aceptado en el programa de posgrado. Para obtener esta probabilidad, se utiliza la función de activación sigmoidal, que transforma el valor de salida en un rango entre 0 y 1, representando una probabilidad.\n",
    "\n",
    "En resumen, la red neuronal implementada en este proyecto consta de una capa de entrada, dos capas densas ocultas y una capa de salida. La función de activación relu se utiliza en las capas ocultas para introducir no linealidad, mientras que la función de activación sigmoidal se utiliza en la capa de salida para obtener la probabilidad de aceptación. Esta configuración se desarrolla con el objetivo de mejorar la eficiencia y precisión en el proceso de admisión en programas de posgrado, utilizando datos relevantes de los solicitantes para realizar predicciones de probabilidad de admisión más precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "topOCmdteSgm"
   },
   "source": [
    "## 4. Desarrollo matemático de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9euLlEr0gGy-"
   },
   "source": [
    "### 4.1 Formulación \n",
    "<t align=\"justify\">\n",
    "\n",
    "La formulación a continuación es para una red neuronal con una única neurona de salida, pero el algoritmo puede aplicarse a una red con cualquier número de salidas mediante la aplicación consistente de la regla de la cadena y la regla de la potencia. Por lo tanto, en todos los ejemplos siguientes, los pares de entrada-salida tendrán la forma $(\\vec{x}, y)$, es decir, el valor objetivo $y$ no será un vector.\n",
    "\n",
    "Mantendremos la misma notación que antes:\n",
    "- $k$: representa la cantidad de capas dentro de la red Feedforward, que en este caso son dos, por lo que $k\\in \\{0,1,2,3\\}$.\n",
    "- $w_{ij}^k$: es el peso del nodo $j$ en la capa $l_k$ hacia el siguiente nodo $i$ en la capa $l_{k-1}$.\n",
    "- $b_i^k$: sesgo para el nodo $i$ en la capa $l_k$\n",
    "- $z_i^k$: suma con pesos más el sesgo en el nodo $i$ en la capa $l_k$.\n",
    "- $a_i^k$: salida del nodo $i$ en la capa $l_k$.\n",
    "- $r_k$: número de nodos en la capa $l_k$.\n",
    "- $g$: función de activación para los nodos de la capa oculta.\n",
    "- $g_o$: función de activación para los nodos de la capa de salida.\n",
    "\n",
    "La función de pérdida (error) será el Error Cuadrado Media (MSE):\n",
    "$$J(X, \\theta) = \\frac{1}{2N}\\sum_{i=1}^N (\\hat{y}_i, y_i)^2$$\n",
    "\n",
    "donde $y_i$ es el valor de salida de $(\\vec{x}_i, y_i)$ y $\\hat{y}_i$ es la salida calculada por la red. Se pueden usar otras funciones de error, pero la asociación histórica del error cuadrático medio con la retropropagación y sus convenientes propiedades matemáticas lo convierten en una buena elección para aprender el método."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrSpljL-eSgm"
   },
   "source": [
    "### 4.2 Backpropagation\n",
    "<t align=\"justify\">\n",
    "\n",
    "La derivación del algoritmo de retropropagación es bastante directa. Se deriva del uso de la regla de la cadena y la regla del producto en cálculo diferencial. La aplicación de estas reglas depende de la diferenciación de la función de activación, una de las razones por las cuales no se utiliza la función de paso de Heaviside (al ser discontinua, no es diferenciable).\n",
    "\n",
    "Para el resto de esta sección, la derivada de una función $f(x)$ se denotará como $f'(x)$, por lo que la derivada de la función sigmoide será $\\sigma'(x)$.\n",
    "\n",
    "Para simplificar aún más las matemáticas, el sesgo $b_i^k$ para el nodo $i$ en la capa $k$ se incorporará en los pesos como $w_{0i}^k$ con una salida fija de $b_0^-1 = 1$ para el nodo $0$ en la capa $(k-1)$. Por lo tanto, $b_i^k = w_{0i}^k$.\n",
    "Para ver que esto es equivalente a la formulación original, observemos que: \n",
    "$$z_i^k=b_i^k+\\sum_{j=1}^{r_k-1}w_{ji}^k a_j^{k-1}=\\sum_{j=0}^{r_k-1}w_{ji}^k a_j^{k-1}$$\n",
    "\n",
    "\n",
    "Utilizando la notación anterior, backpropagation intenta minimizar la siguiente función de error con respecto a los pesos de la red neuronal: $$J(X,\\theta)=\\frac{1}{2N}\\sum_{i=1}^N (\\hat{y}_i, y_i)^2$$\n",
    "\n",
    "calculando $\\frac{\\partial J}{\\partial w_{ij}^k}$ para cada valor de $w_{ij}^k$. Dado que la función de error se puede descomponer en una suma de términos de error individuales para cada par de entrada-salida individual, la derivada se puede calcular con respecto a cada par de entrada-salida de forma individual y luego combinar al final (ya que la derivada de la suma de funciones es la suma de las derivadas de cada función):\n",
    "$$\\frac{\\partial J(X,\\theta)}{\\partial w_{ij}^k} = \\frac{1}{N}\\sum_{d=1}^N \\frac{\\partial }{\\partial w_{ij}^k}\\Big ( \\frac{1}{2}(\\hat{y}_d, y_d)^2 \\Big ) = \\frac{1}{N} \\sum_{d=1}^N \\frac{\\partial J_d}{\\partial w_{ij}^k}$$\n",
    "\n",
    "Por lo tanto, con el fin de derivar el algoritmo de backpropagation, nos enfocaremos en un solo par de entrada-salida. Una vez que se haya derivado esto, se puede generar la forma general para todos los pares de entrada-salida en X combinando los gradientes individuales. Por lo tanto, la función de error en cuestión para la derivación es la siguiente: \n",
    "$$ J = \\frac{1}{2}(\\hat{y}-y)^2,$$\n",
    "donde los subíndices $d$ de $J_d$, $\\hat{y}_d$ y $y_d$ se omiten por simplificación.\n",
    "\n",
    "#### **Derivadas de la función de pérdida**\n",
    "\n",
    "La derivación del algoritmo de retropropagación comienza aplicando la regla de la cadena a la derivada parcial de la función de error\n",
    "$$\\frac{\\partial J}{\\partial w_{ij}^k}= \\frac{\\partial J}{\\partial z_{j}^k} \\frac{\\partial z_j^k}{\\partial w_{ij}^k}$$\n",
    "\n",
    "\n",
    "donde $z_j^k$ es la activación (producto-suma más sesgo) del nodo $j$ en la capa $k$ antes de que se pase a la función de activación no lineal (en este caso, la función sigmoide) para generar la salida. Esta descomposición de la derivada parcial básicamente dice que el cambio en la función de error debido a un peso es el producto del cambio en la función de error $J$ debido a la activación $z_j^k$ multiplicado por el cambio en la activación $z_j^k$ debido al peso $w_{ij}^k$.\n",
    "\n",
    "\n",
    "El primer término se suele llamar \"error\" y se denota como $\\delta_j^k$,\n",
    "$$\\delta_j^k \\equiv \\frac{\\partial J}{\\partial z_{j}^k}.$$\n",
    "\n",
    "\n",
    "El segundo término se puede calcular a partir de la ecuación para $z_j^k$:\n",
    "$$\\frac{\\partial z_j^k}{\\partial w_{ij}^k} = \\Big ( \\sum_{l=0}^{r_k-1} w_{lj}^k a_l^{k-1} \\Big ) = a_l^{k-1}$$\n",
    "\n",
    "Por lo tanto, la derivada parcial de la función de error $J$ con respecto al peso $w_{ij}^k$ es:\n",
    "$$\\frac{\\partial J}{\\partial w_{ij}^k}= \\delta_j^k a_i^{k-1}$$\n",
    "\n",
    "\n",
    "Por lo tanto, la derivada parcial de un peso es un producto del término de error $\\delta_j^k$ en el nodo $j$ de la capa $k$ y la salida $a_i^{k-1}$ del nodo $i$ en la capa $k-1$. Esto tiene sentido intuitivo ya que el peso $w_{ij}^k$ conecta la salida del nodo $i$ en la capa $k-1$ a la entrada del nodo $j$ en la capa $k$ en el grafo de cálculo.\n",
    "\n",
    "Es importante tener en cuenta que las derivadas parciales anteriores se han calculado sin tener en cuenta una función de error o una función de activación específica. Sin embargo, dado que todavía es necesario calcular el término de error $\\delta_j^k$, que depende de la función de error E, en este punto es necesario introducir funciones específicas para ambos. Como se mencionó anteriormente, la propagación hacia atrás clásica utiliza la función de error cuadrático medio (que es la función de error al cuadrado para el caso de un solo par de entrada-salida) y la función de activación sigmoide.\n",
    "\n",
    "El cálculo del error $\\delta_j^k$ se mostrará como dependiente de los valores de los términos de error en la siguiente capa. Por lo tanto, el cálculo de los términos de error procederá hacia atrás desde la capa de salida hasta la capa de entrada. Aquí es donde la propagación hacia atrás, o propagación hacia atrás de errores, obtiene su nombre.\n",
    "\n",
    "##### **La capa de salida**\n",
    "\n",
    "Comenzando desde la capa final, la propagación hacia atrás intenta definir el valor $\\delta_1^m$, donde $m$ es la capa final (el subíndice es $1$ en lugar de $j$ porque esta derivación se refiere a una red neuronal de una sola salida, por lo que solo hay un nodo de salida $j=1$). Por ejemplo, una red neuronal de cuatro capas tendrá $m=3$ para la capa final, $m=2$ para la penúltima capa, y así sucesivamente. Expresar la función de error $J$ en términos del valor $z_1^m$ (ya que $\\delta_1^m$ es una derivada parcial con respecto a $z_1^m$) da como resultado:\n",
    "\n",
    "$$J = \\frac{1}{2} (\\hat{y} - y)^2 = \\frac{1}{2} (g_o(z_1^m) - y)^2,$$\n",
    "\n",
    "Donde $g_o$ es la función de activación de la capa de salida.\n",
    "\n",
    "Dado esto, podemos encontrar la derivada parcial $\\delta_1^m$ usando la regla de la cadena, nos queda\n",
    "\n",
    "$$\\delta_1^m = \\Big ( g_o(z_1^m) - y \\Big ) g'_o(z_1^m) =(\\hat{y}-y)g'_o(z_1^m)$$\n",
    "\n",
    "Juntándolo todo, la derivada parcial de la función de error $J$ con respecto a un peso en la capa final $w_{i1}^m$ es:\n",
    "$$\\frac{\\partial J}{\\partial w_{ij}^m}= \\delta_j^k a_i^{m-1}= (\\hat{y}-y)g'_o(z_1^m)a_i^{m-1}$$\n",
    "\n",
    "\n",
    "##### **Las capas de ocultas**\n",
    "\n",
    "Ahora surge la pregunta de cómo calcular las derivadas parciales de las capas que no son la capa de salida. Afortunadamente, la regla de la cadena para funciones multivariables viene al rescate nuevamente. Observa la siguiente ecuación para el término de error $\\delta_j^k$ en la capa $1 ≤ k < m$:\n",
    "\n",
    "$$\\delta_j^k = \\frac{\\partial J}{\\partial z_j^k} = \\sum_{l=1}^{r^{k+1}} \\frac{\\partial J}{\\partial z_l^{k+1}} \\frac{\\partial z_l^{k+1}}{\\partial z_l^{k}}$$\n",
    "\n",
    "donde $l$ varía de $1$ a $r^{k+1}$ (el número de nodos de la siguiente capa). Observemos que, debido a que la entrada de sesgo $b_0^k$ correspondiente a $w_{0j}^{k+1}$ está fija, su valor no depende de las salidas de las capas anteriores, y por lo tanto $l$ no toma el valor 0.\n",
    "\n",
    "Sustituyendo el término $\\delta_j^{k+1}$ tenemos la siguiente ecuación:\n",
    "$$\\delta_j^k = \\sum_{l=1}^{r^{k+1}} \\delta_l^{k+1} \\frac{\\partial z_l^{k+1}}{\\partial z_l^{k}}$$\n",
    "\n",
    "Además, recordemos que:\n",
    "$$z_l^{k+1} = \\sum_{j=1}^{r^{k}} w_{ji}^{k+1}g(z_j^k),$$\n",
    "\n",
    "donde $g$ es la función de activación de las capas ocultas, \n",
    "$$\\frac{\\partial z_l^{k+1}}{\\partial z_j^{k}} = w_{jl}^{k+1}g'(z_j^k)$$\n",
    "\n",
    "Sustituyendo esto en la ecuación anterior se obtiene una ecuación final para el término de error $\\delta_j^k$ en las capas ocultas, llamada fórmula de retropropagación (backpropagation):\n",
    "$$\\delta_j^k = \\sum_{l=1}^{r^{k+1}} \\delta_l^{k+1} w_{jl}^{k+1}g'(z_j^k) = g'(z_j^k) \\sum_{l=1}^{r^{k+1}} \\delta_l^{k+1} w_{jl}^{k+1}$$\n",
    "\n",
    "Juntando todo esto, la derivada parcial del error $J$ con respecto a los pesos en las capas ocultas $w_{ij}^k$ para $1\\le k<m$:\n",
    "$$\\frac{\\partial J}{\\partial w_{ij}^k} = \\delta_j^k a_i^{k-1} = g'(z_j^k)a_i^{k-1} \\sum_{l=1}^{r^{k+1}} \\delta_l^{k+1} w_{jl}^{k+1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cdqUd8veSgm"
   },
   "source": [
    "Consideremos que en el caso descrito, la función de activación de las capas intermedias es la ReLU (Rectified Linear Unit) que es una función de activación ampliamente utilizada en redes neuronales. Recordemos que su definición es:\n",
    "$$\n",
    "g(x) = relu(x) = max(0, x)\n",
    "$$\n",
    "\n",
    "La derivada de la función relu se puede calcular de la siguiente manera:\n",
    "\n",
    "- Si $x > 0$, la derivada de $g'(x)$ es 1.\n",
    "- Si $x <= 0$, la derivada de $g'(x)$ es 0.\n",
    "\n",
    "En otras palabras, la derivada de $relu(x)$ es 1 cuando el valor de $x$ es positivo, y es 0 cuando el valor de $x$ es negativo o cero. Es importante tener en cuenta que la derivada en $x = 0$ no está definida debido a la discontinuidad en ese punto. Sin embargo, en la práctica, se suele considerar que la derivada en $x = 0$ es 0 para simplificar los cálculos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTzRDlRWeSgm"
   },
   "source": [
    "### 4.2 Descenso de gradiente\n",
    "\n",
    "<center><img src='https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/gradient_descent.png?raw=true' width=800> </center>\n",
    "<t align=\"justify\">\n",
    "El algoritmo de backpropagation es un componente clave del proceso de entrenamiento de una red neuronal. A través de backpropagation, la red ajusta sus pesos y sesgos de manera iterativa para minimizar una función de pérdida, lo que implica encontrar los valores óptimos que minimizan el error de predicción.\n",
    "\n",
    "En el contexto del descenso de gradiente, el algoritmo de backpropagation se utiliza para calcular los gradientes de los pesos y sesgos de la red neuronal en cada iteración del proceso de entrenamiento. Estos gradientes representan la dirección y magnitud de la mayor pendiente descendente de la función de pérdida en el espacio de parámetros de la red.\n",
    "\n",
    "A continuación, se describe cómo el descenso de gradiente se utiliza en conjunto con el algoritmo de backpropagation para entrenar la red neuronal:\n",
    "\n",
    "Inicialización: Se inicializan aleatoriamente los pesos y sesgos de la red neuronal.\n",
    "\n",
    "**Propagación hacia adelante:** Se propaga hacia adelante una entrada a través de la red neuronal, calculando las salidas de cada capa hasta llegar a la capa de salida. Esto implica aplicar las operaciones de suma ponderada y activación en cada neurona de la red.\n",
    "\n",
    "**Cálculo de la pérdida:** Se calcula la función de pérdida entre la salida predicha por la red y la salida deseada (etiqueta) correspondiente al ejemplo de entrenamiento.\n",
    "\n",
    "**Retropropagación del error:** Se calculan los gradientes de los pesos y sesgos de la red utilizando el algoritmo de backpropagation. Este proceso implica calcular el gradiente de la función de pérdida con respecto a los pesos y sesgos de cada capa, propagando el error hacia atrás a través de la red neuronal.\n",
    "\n",
    "**Actualización de los parámetros:** Utilizando los gradientes calculados, se actualizan los pesos y sesgos de la red utilizando el descenso de gradiente. Se multiplican los gradientes por una tasa de aprendizaje y se restan de los parámetros actuales para moverse en la dirección opuesta al gradiente y así minimizar la función de pérdida.\n",
    "\n",
    "**Repetición:** Se repiten los pasos 2 a 5 para cada ejemplo de entrenamiento en el conjunto de datos.\n",
    "\n",
    "**Iteraciones:** Se repiten los pasos 2 a 6 durante varias iteraciones (épocas) para entrenar la red neuronal. Cada iteración ajusta gradualmente los pesos y sesgos de la red, refinando las predicciones y reduciendo el error.\n",
    "\n",
    "Al repetir estos pasos iterativamente y ajustar los pesos y sesgos en la dirección descendente del gradiente, la red neuronal busca encontrar los valores óptimos que minimizan la función de pérdida y logran un buen rendimiento en la tarea de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljwVb4RxeSgn"
   },
   "source": [
    "## 5. Redes convolucionales: Fundamentos teóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1P-_USPieSgn"
   },
   "source": [
    "<t align=\"justify\">\n",
    "Las redes convolucionales (LeCun, 1989), también conocidas como redes neuronales convolucionales o CNN, son un tipo especializado de red neuronal diseñada para procesar datos que tienen una topología conocida en forma de una malla o cuadrícula.\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/VGG16_1.png?raw=true width=600> </center>\n",
    "\n",
    "Comencemos explicando cada elemento básico dentro de la red neuronal convolucional.\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/Basic_CNN.png?raw=true width=600> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRkgYACZeSgn"
   },
   "source": [
    "### 5.1  **Capa de entrada**\n",
    "<t align=\"justify\">\n",
    "Las entradas de la red neuronal VGG16 corresponden con las imagenes de $224 \\times 224$ pixeles. \n",
    "\n",
    "Recordemos que los colores se miden en escala RGB, es decir, cada pixel dentro de una imágen va a estar asociado a tres valores (rojo, verde y azul), así, podemos pensar a una imágen de 224x224 como un objeto que para cada canal de color posee una matriz de valores.\n",
    "\n",
    "Dentro de procesamiento de imágenes, una imagen a color puede representarse como un tensor de tres dimensiones (generalización de matrices en tres deimensiones).\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/imagenrgb.png?raw=true width=400> </center>\n",
    "\n",
    "Podemos definir tal tensor de la siguiente manera.\n",
    "Sea $\\mathbb{Z}_{255} = \\{x \\in \\mathbb{Z} |  0\\le x\\le 255\\}$, es decir, el conjunto de los enteros que van desde 0 hasta 255. Definimos al tensor $X_{i,j,k}$ como $$X_{i,j,k} \\in \\mathbb{Z}_{255}^{224 \\times 224 \\times 3},$$\n",
    "Donde:\n",
    "- $X_{i,j,k}$ representa la imagen de entrada a la red convolucional. \n",
    "- $k$ es el subíndice que representa el canal de color, por lo que al fijar el valor de $k$, digamos $X_{i,j, 1}$, representará una matriz de $i\\times j$ en el canal rojo en la escala RGB, que tiene como entradas valores enteros que van desde 0 hasta 255.\n",
    "- $i$ es el renglón de la matriz, es decir, es la posición vertical de cada pixel. \n",
    "- $j$ representa la columna de la matriz, es decir, la posición horizontal del pixel.\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/tensores.png?raw=true width=400> </center>\n",
    "\n",
    "En lo siguiente, haremos referencia a la representación en forma de función $I(x,y)$ de una imagen. Definimos $$I(x,y) = (R(x,y), G(x,y), B(x,y)),$$ donde $(x,y)$ son las coordenadas espaciales de un pixel dentro de la imagen y $(R, G, B)$ son los valores de color correspondientes en ese pixel. \n",
    "\n",
    "Para realizar la conexión de ambas representaciones podemos pensar en una imagen como una función que a cada pixel $(x,y)$ le asigna una tripleta de valores numéricos $(R,G,B)$. De esta manera, podemos pensar a $I$ como una función $I: \\mathbb{Z}^2 \\to \\mathbb{Z}_{255}^3$, donde\n",
    "$$R(x, y) = X_{x, y, 1}$$\n",
    "$$G(x, y) = X_{x, y, 2}$$\n",
    "$$B(x, y) = X_{x, y, 3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAvXkS5zeSgn"
   },
   "source": [
    "### 5.2 **Capa convolucional**\n",
    "<t align=\"justify\">\n",
    "\n",
    "Esta capa es la primera capa oculta que se utiliza para extraer características de la imagen de entrada. Se encuentra compuesta de los elementos que se describen a continuación.\n",
    "\n",
    "#### **Filtros:** \n",
    "\n",
    "También conocidos como núcleos o kernels, son matrices de pesos que se deslizan sobre los datos de entrada. Cada filtro extrae características específicas de los datos mediante la operación de convolución.\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/Kernels.png?raw=true width=600> </center> \n",
    "\n",
    "En el contexto de procesamiento de imágenes, un filtro es una matriz o tensor que contiene valores numéricos utilizados para realizar la convolución con una imagen. Estos valores numéricos especifican cómo se deben combinar los píxeles vecinos para obtener los nuevos valores de píxeles en la imagen de salida. Los filtros se utilizan para realizar diversas operaciones de procesamiento de imágenes, como el filtrado espacial, la detección de bordes, la suavización, entre otros.\n",
    "\n",
    "Estos representan los pesos que la red neuronal va a aprender.\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/Filtro.png?raw=true width=600> </center>\n",
    "\n",
    "\n",
    "#### **Operación de convolución:** \n",
    "Es la operación fundamental realizada en una capa convolucional. Consiste en deslizar los filtros sobre los datos de entrada y calcular la suma ponderada de los elementos de la entrada cubiertos por el filtro en cada posición.\n",
    "\n",
    "En las aplicaciones de procesamiento de imagen, la convolución de distintos “filtros\" sobre una imagen es una herramienta habitual empleada en problemas de segmentación, detección de bordes o reducción de imagen. No obstante, los valores de\n",
    "dichos filtros deben ser establecidos a priori, lo que requiere experiencia en el campo\n",
    "y a menudo largos procesos de ajuste de parámetros al problema en cuestión. En\n",
    "contraposición, las redes convolucionales parten de una serie de filtros aleatorios\n",
    "que se ajustan de manera automática mediante el proceso de aprendizaje de la red.\n",
    "\n",
    "En matemáticas, una convolución es una operación matemática sobre dos funciones (f y g) que produce una tercera función que expresa como la forma de una de ellas fue modificada por la otra. En otras palabras, una convolución es una manera de aplicar un filtro a una función y obtener otra función como resultado.\n",
    "\n",
    "En particular, en procesamiento de imágenes, una convolución es una operación matemática que se utiliza para combinar una imagen de entrada con un filtro o kernel para obtener una imagen de salida. La convolución se realiza deslizando el kernel sobre la imagen de entrada y calculando el producto punto entre los elementos del kernel y los píxeles correspondientes en la imagen. Luego, se suma el resultado de estos productos para obtener el valor de cada píxel en la imagen de salida.\n",
    "\n",
    "Para definir estos elementos, nos concentraremos en un solo canal de color de la imagen para trabajar en elementos de dos dimensiones. Fijamos el canal $c$, de esta manera $X = (x_{i,j}) \\in M_{i\\times j}(\\mathbb{Z}_{255})$ representa una matriz de $i\\times j$ con entradas enteras no negativas de 0 a 255 en el canal de color fijo $c$. \n",
    "\n",
    "Así, de manera correspondiente, la representación funcional de la imagen quedaría definida como, $I: \\mathbb{Z}^2 \\to \\mathbb{Z}_{255}$, con $$I(i,j) := x_{i,j}$$\n",
    "\n",
    "Un kernel dentro de este contexto es una matriz cuadrada pequeña que se aplica a la imagen mediante la convolución. Podríamos pensar en este kernel como un filtro, que tiene un efecto sobre la imagen de entrada. Cada elemento del kernel especifica el peso o la contribución relativa de un píxel vecino en la generación del valor de un píxel en la imagen de salida.\n",
    "\n",
    "**Definición de convolución:** \n",
    "Formalmente, la convolución de una imagen de entrada $I(i, j)$ con una matriz de $n\\times m$ llamado kernel (filtro) $K(m, n)$, se denota por $S=I*K$ y se puede definir como sigue:\n",
    "$$S(i, j) = (I*K)(i,j)= \\sum_{m} \\sum_{n} I(i-m, j-n) K(m, n)\n",
    "$$\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/2D_Convolution_Animation.gif?raw=true width=600> </center>\n",
    "\n",
    "En la terminología de las redes convolucionales, el primer argumento (en este ejemplo, la función I) de la convolución se suele denominar entrada, y el segundo argumento (en este ejemplo, la función K) se llama núcleo o filtro. La salida a veces se denomina mapa de características.\n",
    "\n",
    "La convolución con imágenes a color se define de manera similar a la convolución con imágenes en escala de grises, pero se realiza teniendo en cuenta los canales de color adicionales. En este caso, se realizan operaciones de convolución separadas en cada canal de color de la imagen.\n",
    "\n",
    "Supongamos que tenemos una imagen a color compuesta por tres canales: rojo (R), verde (G) y azul (B). Para realizar la convolución con una imagen a color, se aplicará la convolución de manera independiente en cada canal de color utilizando un filtro o kernel correspondiente.\n",
    "\n",
    "Cada capa de convolución dentro de la red neuronal VGG16 está compuesto con filtros de $3\\times 3$, así una capa de convolución está compuesta por $N$ filtros $W$ de dimensión $3 \\times 3 \\times 3$.\n",
    "Dada una entrada $X$ de dimensión $h \\times w \\times 3$, cada uno de los filtros de convolución\n",
    "se coloca sobre cada ventana de tamaño $3 \\times 3 \\times 3$ centrada en cada píxel $x_{i,j}$ de $X$.\n",
    "El filtro de convolución se va desplazando a lo largo de toda la imagen, tras aplicar\n",
    "la convolución a cada una de las ventanas de la imagen. La salida $Z_{i,j}$ generada\n",
    "para la ventana centrada en el pixel $x_{i,j}$ se calcula en base a la siguiente fórmula:\n",
    "$$Z_{i,j} = \\sum_{d=1}^3 \\sum_{n=1}^3 \\sum_{m=1}^3 X_{i+m-\\frac{k+1}{2}, j+n-\\frac{k+1}{2}, d}\\cdot W_{m,n,d}$$\n",
    "\n",
    "Al resultado $Z$ producido por un filtro de convolución se le llama imagen de\n",
    "características, dado que ofrece información sobre la presencia o ausencia de la característica buscada por el filtro en cuestión. Dado que se cuenta con $N$ filtros de convolución, se generarán $N$ imágenes de características que, para poder ser tratadas de\n",
    "manera cómoda por las siguientes capas de la red, se apilan unas con otras, dando\n",
    "lugar a una imagen de características tridimensional. Así, el canal $d$-ésimo de $Z$\n",
    "contiene el resultado de aplicar el filtro de convolución $d$-ésimo a $X$\n",
    "\n",
    "#### **Mapas de características:** \n",
    "Cada filtro produce un mapa de características, que es una representación en 2D de las características extraídas en cada posición. Cada mapa de características se obtiene aplicando el filtro correspondiente a la entrada y realizando la convolución. Podríamos pensar al mapa de características como la salida que obtenemos a partir de la convolución.\n",
    "\n",
    "#### **Función de activación ReLU:** \n",
    "Después de la convolución, se aplica una función de activación no lineal a cada elemento del mapa de características para introducir no linealidad en la red. La función de activación más comúnmente utilizada en las capas convolucionales es la función ReLU (Rectified Linear Unit), y es la que utiliza la red propuesta.\n",
    "\n",
    "Recordemos que la función ReLU se define como $$f(x)=\\max(0, x)$$\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/ReLU.png?raw=true width=600> </center>\n",
    "\n",
    "Podríamos pensar en la función de activación como una forma de asignar puntuaciones a los valores de píxeles según alguna medida de importancia. La activación ReLU establece que los valores negativos no son importantes y los convierte en 0. Esta función se aplica a cada término del mapa de características.\n",
    "\n",
    "Existen varias razones para utilizar esta función de activación y todas estas tienen que ver con facilitar el trabajo posterior:\n",
    "\n",
    "- **No linealidad:** ReLU introduce no linealidad a la red, lo que permite que la red aprenda representaciones más complejas y expresivas. ReLU es una función no lineal simple pero efectiva que introduce no linealidad sin ser computacionalmente costosa.\n",
    "\n",
    "- **Activación dispersa:** ReLU proporciona dispersión en las activaciones. Dado que ReLU establece los valores negativos en cero, introduce dispersión en la red, lo que significa que solo un subconjunto de neuronas se activa. Las activaciones dispersas ayudan a reducir la complejidad computacional, los requisitos de memoria y el sobreajuste al enfocarse en las características más relevantes.\n",
    "\n",
    "- **Problema del gradiente desvaneciente:** ReLU ayuda a mitigar el problema del gradiente desvaneciente, que puede ocurrir durante la retropropagación en redes neuronales profundas. La derivada de ReLU es 0 o 1, proporcionando un gradiente constante para entradas positivas. Esto evita la saturación de los gradientes y facilita un mejor flujo de gradientes, lo que permite un entrenamiento más estable y eficiente.\n",
    "\n",
    "- **Eficiencia:** ReLU es computacionalmente eficiente en comparación con otras funciones de activación como sigmoidal o tangente hiperbólica, ya que involucra operaciones simples elemento a elemento y no requiere cálculos exponenciales costosos.\n",
    "\n",
    "\n",
    "En la red VGG16 se tienen 5 capas convolucionales, con una cantidad pequeña de filtros de $3\\times 3$.\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/conv1.png?raw=true width=800> </center>\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/esquema_conv.png?raw=true width=600> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VafHO5xNeSgn"
   },
   "source": [
    "### 5.3 Capa de agrupamiento (Max Pooling)\n",
    "<t align=\"justify\">\n",
    "\n",
    "Para que el proceso anterior sea útil, el número de filtros aprendidos en la red deberá ser elevado, y por consiguiente, la dimensionalidad de la imagen de características aumentará notablemente. Dado que la eficiencia y facilidad de entrenamiento del clasificador de nuestra red mejorarán si se opera sobre un vector de características de pocos atributos, resulta necesario reducir la imagen de características generada. Es aquí donde las capas de “pooling\" entran en juego.\n",
    "\n",
    "La capa de agrupamiento Max Pooling se realiza dividiendo cada mapa de características en regiones no superpuestas y tomando el valor máximo de cada región, esto es, para cada región se selecciona únicamente el valor máximo y se descartan los otros valores. El resultado de esta capa es un mapa de características con dimensionalidad reducida. La función de estas capas es la de reducir la imagen de características gradualmente, tratando de preservar la máxima información significativa posible.\n",
    "\n",
    "Esta capa de agrupamiento es una operación comunmente utilizada entre las capas intermedias convolucionales, y su principal función es reducir la dimensionalidad espacial de los mapas de características y poder extraer las características más relevantes en una red convolucional.\n",
    "\n",
    "El max pooling es una operación no lineal y no tiene parámetros entrenables.\n",
    "\n",
    "En la red VGG16, el maxpooling que se utiliza es de tamaño de agrupamiento de $2\\times 2$ y con stride de $2$. Esto significa que este Max Pooling divide la entrada en ventanas disjuntas considerando un paso o stride de 2 espacios. Por esta razón nos limitaremos a este tipo de pooling. Un dato adicional es que este pooling reduce la dimensionalidad en un factor de $2\\times 2$.\n",
    "\n",
    "Dada una entrada $A$ de tamaño $H\\times W \\times C$ donde $H\\times W$ es la dimensión espacial y $C$ el número de canales, y un tamaño de agrupamiento o ventana $2\\times 2$, con tamaño de paso $2$, la operación de agrupamiento puede representarse de la siguiente manera.\n",
    "\n",
    "La matriz de entrada $A$ se descompone en ventanas disjuntas que denotaremos por $A^{\\alpha \\beta}$ de dimensión $2\\times 2 \\times c$. Por cada canal se lleva a cabo la siguiente operación:\n",
    "$$Y^{\\alpha \\beta}_c = \\max(X^{\\alpha \\beta}_c)$$ \n",
    "\n",
    "El paso de $A$ a través de una capa de pooling de tamaño $k \\times k$, reduce el número\n",
    "de atributos por un factor de $k \\times k$. Las sucesivas capas de pooling de la red siguen\n",
    "reduciendo el número de atributos, hasta llegar a un número aceptable para el clasificador de la red.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w77azziueSgo"
   },
   "source": [
    "### 5.4 Capa Flatten\n",
    "<t align=\"justify\">\n",
    "\n",
    "Después de terminar las capas precias, deberíamos tener un mapa de características agrupadas (pooled). En la capa flatten, como su nombre lo indica, vamos a \"aplanar\" nuestro mapa de características a una sola columna, como se muestra en la imagen:\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/Flattening.png?raw=true width=600> </center>\n",
    "\n",
    "\n",
    "La idea de la capa flatten es simplemente pasar de matrices o tensores a un solo vector, es decir, se trata solamente de un reacomodo de los elementos del tensor para obtener un vector de unidimensional. Es importante destacar que en esta capa no se introducen parámetros entrenables, ya que solo se trata de un reacomodo. \n",
    "\n",
    "La capa Flatten se utiliza para permitir un procesamiento adicional en capas completamente conectadas dentro de la red convolucional.\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/flattening1.png?raw=true width=600> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zlwl2otweSgo"
   },
   "source": [
    "### 5.5 Capa densa (Fully-connected)\n",
    "<t align=\"justify\">\n",
    "\n",
    "Las capas fully-connected dentro de las redes convolucionales se encuentran tipicamente al final de la arquitectura después de la capa flattening. Son aquellas capas en las que todas las entradas de una capa están conectadas a cada unidad de activación de la siguiente capa. En la mayoría de los modelos populares de aprendizaje automático, las últimas capas son capas fully connected, que compilan los datos extraídos por las capas anteriores para formar la salida final.\n",
    "\n",
    "Después de nuestras 13 capas convolucionales, conectamos nuestra capa plana a 3 capas fully connected (totalmente conectadas). Una pregunta muy natural es por qué usamos capas fully connected en absoluto. La razón por la que no querríamos usarlas es la enorme cantidad de parámetros de peso en la primera capa fully connected:\n",
    "\n",
    "$512 * 7 * 7 * 4096 = 102,760,448$ parámetros de peso conectan la capa plana a la primera capa fully connected.\n",
    "\n",
    "Podemos pensar en las capas convolucionales y de pooling como la creación de representaciones útiles de los datos. Recuerda que ambas operaciones son locales en el sentido de que tienen en cuenta ventanas de los datos. Las capas fully connected, en cambio, son globales y conectan cada valor en la capa de max pooling anterior ($\\bold{m}^{[13]}$) juntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3I9-he_eSgo"
   },
   "source": [
    "### 5.6 Capa de salida\n",
    "<t align=\"justify\">\n",
    "El último paso es conectar nuestra última capa fully connected ($\\bold{a}^{[16]}$) a nuestra capa de salida ($\\hat{y}$). Para hacer esta transición, debemos usar una función de activación. \n",
    "\n",
    "En la arquitectura VGG16 se utiliza la función de activación softmax en la última cpa, pero dado que nuestro problema se trata de clasificación binaria, cambiamos esta capa por una sola neurona con función de activación sigmoidal, lo cual que nos dará como salida un solo valor $\\hat{y}$ que representa la probabilidad de pertenencia a la clase \"melanoma\".\n",
    "\n",
    "Veamos un diagrama que describe la arquitectura de la red convolucional a utilizar:\n",
    "\n",
    "<center><img src=https://github.com/estephaniapa/PropedeuticoRedes/blob/main/A%CC%81lgebra%20lineal%20y%20optimizacio%CC%81n/VGG_15.png?raw=true width=400> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSXFg7freSgo"
   },
   "source": [
    "### 5.7 Forward propagation\n",
    "\n",
    "<t align=\"justify\">\n",
    "\n",
    "Realizaremos el desarrollo matemático de la red neuronal que utilizamos (Forward propagation).\n",
    "\n",
    "\n",
    "Primero, vamos a definir los símbolos utilizados en las ecuaciones:\n",
    "\n",
    "- $X$ representa la entrada a la red neuronal convolucional.\n",
    "- $W$ representa los pesos de la capa convolucional.\n",
    "- $b$ representa los sesgos (biases) de la capa convolucional.\n",
    "- $A$ representa la salida de la capa convolucional.\n",
    "- $\\sigma$ representa la función de activación, que en este caso asumiremos que es la función ReLU.\n",
    "- $\\ast$ representa la operación de convolución.\n",
    "- $\\oplus$ representa la operación de suma.\n",
    "\n",
    "A continuación se muestra el desarrollo matemático de una CNN16:\n",
    "\n",
    "1. Convolución de la primera capa:\n",
    "$$Z^{[1]} = X \\ast W^{[1]} + b^{[1]}$$\n",
    "$$A^{[1]} = \\sigma(Z^{[1]})$$\n",
    "\n",
    "2. Convolución de la segunda capa:\n",
    "$$Z^{[2]} = A^{[1]} \\ast W^{[2]} + b^{[2]}$$\n",
    "$$A^{[2]} = \\sigma(Z^{[2]})$$\n",
    "\n",
    "3. Capa de agrupación (pooling) de la segunda capa:\n",
    "$$A^{[2]}_{\\text{pooled}} = \\text{MaxPooling}(A^{[2]})$$\n",
    "\n",
    "4. Convolución de la tercera capa:\n",
    "$$Z^{[3]} = A^{[2]}_{\\text{pooled}} \\ast W^{[3]} + b^{[3]}$$\n",
    "$$A^{[3]} = \\sigma(Z^{[3]})$$\n",
    "\n",
    "5. Convolución de la cuarta capa:\n",
    "$$Z^{[4]} = A^{[3]} \\ast W^{[4]} + b^{[4]}$$\n",
    "$$A^{[4]} = \\sigma(Z^{[4]})$$\n",
    "\n",
    "6. Capa de agrupación de la cuarta capa:\n",
    "$$A^{[4]}_{\\text{pooled}} = \\text{MaxPooling}(A^{[4]})$$\n",
    "\n",
    "7. Repite los pasos 4-6 para las capas 5-8.\n",
    "\n",
    "8. Convolución de la novena capa:\n",
    "$$Z^{[9]} = A^{[8]} \\ast W^{[9]} + b^{[9]}$$\n",
    "$$A^{[9]} = \\sigma(Z^{[9]})$$\n",
    "\n",
    "9. Convolución de la décima capa:\n",
    "$$Z^{[10]} = A^{[9]} \\ast W^{[10]} + b^{[10]}$$\n",
    "$$A^{[10]} = \\sigma(Z^{[10]})$$\n",
    "\n",
    "10. Capa de agrupación de la décima capa:\n",
    "$$A^{[10]}_{\\text{pooled}} = \\text{MaxPooling}(A^{[10]})$$\n",
    "\n",
    "11. Repite los pasos 9-10 para las capas 11-14.\n",
    "\n",
    "12. Convolución de la decimoquinta capa:\n",
    "$$Z^{[15]} = A^{[14]} \\ast W^{[15]} + b^{[15]}$$\n",
    "$$A^{[15]} = \\sigma(Z^{[15]})$$\n",
    "\n",
    "13. Convolución de la decimosexta capa:\n",
    "$$Z^{[16]} = A^{[15]} * W^{[16]} + b^{[16]}$$\n",
    "$$A^{[16]} = σ(Z^{[16]})$$\n",
    "\n",
    "Estas ecuaciones representan el desarrollo matemático de una red neuronal convolucional (CNN) con 16 capas. Cada capa realiza una convolución seguida de una función de activación ReLU, y en algunas capas se realiza también una capa de agrupación (pooling) para reducir la dimensionalidad de las características extraídas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEFyOwu4eSgo"
   },
   "source": [
    "## 6. Bibliografía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eXscdNyeSgs"
   },
   "source": [
    "- Raychev, Nikolay. (2020). Mathematical foundations of neural networks. Implementing a perceptron from scratch. Nature. 67-143. 10.37686/nsr.v1i1.74. Recuperado de [sitio](https://www.researchgate.net/publication/343554356_Mathematical_foundations_of_neural_networks_Implementing_a_perceptron_from_scratch).\n",
    "\n",
    "- Vladimir, I. (21 de Noviembre de 2016). \"Gradient Descent\". Recuperado de [Entrada de blog](https://turing.iimas.unam.mx/~ivanvladimir/posts/gradient_descent/). \n",
    "\n",
    "- Merino Ulizarna, L. (Julio 2022). Uso de una Red Neuronal Convolucional para la detección de cáncer de tipo melanoma. Recuperado de [Documento PDF](https://oa.upm.es/71361/1/TFG_LUIS_MERINO_ULIZARNA.pdf).\n",
    "\n",
    "- Kiprono Elijah Koech. (2022, 02 de Octubre). Cross Entropy Loss Function. Towards Data Science. Recuperado de [Entrada de towards data science](https://towardsdatascience.com/.cross-entropy-loss-function-f38c4ec8643e).\n",
    "\n",
    "- Dharmaraj. (2022, Junio 1). Convolutional Neural Networks (CNN) — Architecture Explained. Medium. Recuperado de [Entrada de medium](https://medium.com/@draj0718/convolutional-neural-networks-cnn-architectures-explained-716fb197b243).\n",
    "\n",
    "- IBM. (Fecha de publicación desconocida). ¿Qué es el descenso de gradiente?. Recuperado de [Web Site de IBM](https://www.ibm.com/mx-es/topics/gradient-descent).\n",
    "\n",
    "- IBM. (Fecha de publicación desconocida). ¿Qué son las redes neuronales?. Recuperado de [Web Site de IBM](https://www.ibm.com/mx-es/topics/neural-networks).\n",
    "\n",
    "- Brilliant.org. (s.f.). Backpropagation. Recuperado de https://brilliant.org/wiki/backpropagation/\n",
    "\n",
    "<script>\n",
    "  document.addEventListener(\"DOMContentLoaded\", function() {\n",
    "    const target = document.querySelector(\"#table-of-contents\");\n",
    "    const toc = ghToc.insert(\"\", target);\n",
    "    target.innerHTML = toc;\n",
    "  });\n",
    "</script>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KH97O06fhBDy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
