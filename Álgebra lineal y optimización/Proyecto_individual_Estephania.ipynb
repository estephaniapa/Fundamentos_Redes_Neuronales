{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto individual: Redes neuronales\n",
    "Álgebra lineal y optimización\n",
    "\n",
    "Estephania Pivac Alcaraz\n",
    "\n",
    "Dr. Espinoza\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Introducción a las redes neuronales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales, también conocidas como redes neuronales artificiales (ANN) o redes neuronales simuladas (SNN), son un subconjunto de algoritmos de machine learning y están en el eje de los algoritmos de deep learning. Su nombre y estructura están inspirados en el cerebro humano, imitando la forma en que las neuronas biológicas se transmiten entre sí.\n",
    "\n",
    "Una red neuronal es una serie de algoritmos que se esfuerzan por reconocer relaciones subyacentes en un conjunto de datos a través de un proceso que imita la forma en que opera el cerebro humano. En este sentido, las redes neuronales se refieren a sistemas de neuronas, ya sean orgánicas o artificiales. Las redes neuronales pueden adaptarse a cambios de entrada, de manera que la red genera el mejor resultado posible sin necesidad de rediseñar los criterios de salida.\n",
    "\n",
    "Las redes neuronales artificiales (ANN), se componen de capas de nodos, que contienen una capa de entrada, una o más capas ocultas, y una capa de salida. Cada nodo, o neurona artificial, se conecta a otro y tiene un peso y un umbral asociados. Si la salida de cualquier nodo individual está por encima del valor de umbral especificado, dicho nodo se activa, enviando datos a la siguiente capa de la red. De lo contrario, no se pasan datos a la siguiente capa de la red.\n",
    "\n",
    "Las redes neuronales se basan en datos de entrenamiento para aprender y mejorar su precisión con el tiempo. Sin embargo, una vez que estos algoritmos de aprendizaje se ajustan con precisión, se convierten en potentes herramientas en ciencias de la computación e inteligencia artificial, lo que nos permite clasificar y agrupar datos a gran velocidad. Las tareas de reconocimiento de voz o reconocimiento de imágenes pueden llevar minutos en lugar de horas en comparación con la identificación manual realizada por expertos humanos. Una de las redes neuronales más conocidas es el algoritmo de búsqueda de Google.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 ¿Qué es una neurona artificial?\n",
    "\n",
    "Las neuronas son simples procesadores de información, que tiene múltiples entradas $x_i$ y una salida $y$. Esta salida la calcula realizando un par de operaciones.\n",
    "<center><img src=\"Imagen1.png\" width=600>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Componentes de una neurona artificial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Imagen2.png\" width=600> </center>\n",
    "\n",
    "1. **Entradas $x_i$:**  Una neurona artificial recibe una serie de entradas numéricas. Cada entrada está asociada con un peso específico que determina la importancia de esa entrada en la salida de la neurona.\n",
    "\n",
    "2. **Pesos $w_i$:** Cada entrada de la neurona tiene asociado un peso, que representa la fuerza de la conexión entre la entrada y la neurona. Los pesos determinan la contribución relativa de cada entrada en la salida de la neurona.\n",
    "\n",
    "    Las entradas y los pesos se multiplican y suman, para calcular la suma ponderada de las entradas. Esta suma ponderada es una combinación lineal de las entradas y los pesos.\n",
    "    $$f(\\mathbf{w}^t \\mathbf{x} +w_0)$$\n",
    "\n",
    "3. **Bias o sesgo $w_0$:**  Además de las entradas y los pesos, una neurona puede tener un sesgo (bias) adicional. El sesgo es un parámetro que se suma a la suma ponderada antes de aplicar la función de activación. El sesgo permite ajustar el punto de activación de la neurona y controlar el umbral de activación.\n",
    "\n",
    "\n",
    "4. **Función de activación $f$:**  La suma ponderada se pasa a través de una función de activación, que introduce no linealidad en la salida de la neurona. Esta determina el rango y la forma de la salida de la neurona. \n",
    "Las funciones de activación son esenciales en las redes neuronales para introducir no linealidad y permitir el aprendizaje de relaciones complejas en los datos. Permiten una mayor representación y expresividad, y son fundamentales para el éxito y la eficacia de las redes neuronales en una amplia gama de aplicaciones.\n",
    "    \n",
    "\n",
    "5. **Salida $y$:** La salida de la neurona artificial, la variable dependiente $y$, se calcula aplicando la función de activación a la suma ponderada más el sesgo. La salida puede ser la salida final de la neurona o puede ser la entrada para otras neuronas en una red neuronal más grande.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1    Perceptrón: Red neuronal de una sola capa (una sola neurona)\n",
    "\n",
    "<center><img src=\"Imagen4.png\" width=600> </center>\n",
    "\n",
    "Las redes neuronales de una sola capa también son llamadas **Perceptrones**.  Este se trata de un algoritmo de clasificación lineal binaria inventado en 1957 por Frank Rosenblatt. Es decir, es un algoritmo que trata de decidir a qué clase de salida pertenece una determinada entrada. El perceptrón es la red neuronal más simple, ya que consta de una sola neurona. Utiliza la función de escalón, también llamada Heaviside, como función de activación.\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x) = \n",
    "\\begin{cases}\n",
    "0, & \\text{si } x < 0 \\\\\n",
    "1, & \\text{si } x \\ge 0\n",
    "\\end{cases}\n",
    "\\end{equation*} \n",
    "\n",
    "\n",
    "El perceptrón lineal simple tiene una principal limitación: no tiene capacidad para resolver problemas que no son linealmente separables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##      1.3  ¿Cómo se forman las redes neuronales?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red neuronal, tanto la biológica como la artificial, consiste en un largo número de unidades simples llamadas neuronas, que reciben y transmiten señales unas con otras. Es decir, consisten de capas de neuronas, y las redes neuronales artificiales multi-capas pueden resolver problemas no linealmente separables.\n",
    "\n",
    "A menudo las arquitecturas de redes neuronales están compuestas por capas de neuronas que se comunican entre sí, principalmente las podemos dividir en:\n",
    "\n",
    "1. **Capa de entrada:** Es la capa inicial de la red neuronal donde se introducen los datos de entrada. Cada neurona en esta capa representa una característica o variable de entrada. No hay cálculos o transformaciones en esta capa, solo se transmiten las entradas a la siguiente capa.\n",
    "\n",
    "2. **Capas ocultas:** Son capas intermedias entre la capa de entrada y la capa de salida. Estas capas realizan cálculos y transformaciones complejas para procesar la información de entrada. Pueden haber una o varias capas ocultas en una red neuronal, y el número de neuronas en cada capa oculta puede variar.\n",
    "\n",
    "3. **Capa de salida:** Es la capa final de la red neuronal donde se obtienen las salidas predichas. La forma y el número de neuronas en esta capa dependen del problema que se esté abordando. Por ejemplo, en problemas de clasificación binaria, se puede utilizar una neurona con una función de activación sigmoide para producir una salida entre 0 y 1. En problemas de clasificación multiclase, se puede utilizar una neurona por clase con una función de activación softmax.\n",
    "\n",
    "<center><img src=\"Imagen6.png\" width=300> </center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    1.4 Arquitecturas de redes neuronales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"image7.png\" width=300> </center>\n",
    "\n",
    "Existen varias arquitecturas de redes neuronales, cada una diseñada para abordar diferentes tipos de problemas y aprender patrones específicos en los datos. A continuación, se presentan algunas de las arquitecturas más comunes de redes neuronales:\n",
    "\n",
    "### 1.4.1 Redes Neuronales Feedforward (FFNN)\n",
    "\n",
    "Una red neuronal feedforward, también conocida como red neuronal de propagación hacia adelante, es un tipo de red neuronal artificial que se utiliza en la mayoría de las aplicaciones de aprendizaje automático y reconocimiento de patrones. Es una red neuronal en la que la información fluye en una sola dirección, desde la entrada hasta la salida, sin bucles ni conexiones hacia atrás.\n",
    "\n",
    "La red neuronal feedforward consta de múltiples capas:\n",
    "- una capa de entrada\n",
    "- una o más capas ocultas\n",
    "- una capa de salida\n",
    "\n",
    "Cada capa consta de un conjunto de nodos o neuronas, que reciben entradas de la capa anterior y generan salidas para la capa siguiente. Los pesos entre los nodos se ajustan durante el entrenamiento de la red neuronal para minimizar el error en la predicción de la salida.\n",
    "\n",
    "El proceso de predicción en una red neuronal feedforward implica alimentar los datos de entrada a través de la capa de entrada y las capas ocultas, y finalmente producir una salida en la capa de salida. Cada capa de la red neuronal utiliza una función de activación no lineal para transformar las entradas y generar las salidas correspondientes. Las funciones de activación más comunes son la función sigmoidal y la función ReLU.\n",
    "\n",
    "Las redes neuronales feedforward son utilizadas en una amplia variedad de aplicaciones de aprendizaje automático, incluyendo la clasificación de imágenes, el procesamiento del lenguaje natural, el reconocimiento de voz, la detección de fraudes, la predicción de series temporales, entre otros.\n",
    "\n",
    "\n",
    "### 1.4.2 Redes Neuronales Recurrentes (RNN)\n",
    "\n",
    "<center><img src=\"image8.jpeg\" width=600> </center>\n",
    "\n",
    "Una red neuronal recurrente (RNN) es un tipo de red neuronal artificial que utiliza datos secuenciales o datos de series de tiempo. Estos algoritmos de aprendizaje profundo se utilizan comúnmente para problemas ordinales o temporales, como la traducción de idiomas, el reconocimiento de voz y subtítulos de imágenes.\n",
    "\n",
    "Cabe mencionar que están incorporados en aplicaciones populares como Siri, búsqueda por voz y Google Translate.\n",
    "Al igual que las redes neuronales feedforward y convolucionales (CNN), las redes neuronales recurrentes utilizan datos de entrenamiento para aprender. Se distinguen por su \"memoria\", ya que toman información de entradas anteriores para utilizarse en los datos de entrada y en los resultados.\n",
    "\n",
    "Si bien las redes neuronales profundas tradicionales asumen que los datos de entrada y los resultados son independientes entre sí, los resultados de las redes neuronales recurrentes depende de los elementos anteriores dentro de la secuencia. Aunque los eventos futuros también serían útiles para determinar los resultados de una secuencia dada, las redes neuronales recurrentes unidireccionales no pueden tener en cuenta estos eventos en sus predicciones.\n",
    "\n",
    "\n",
    "### 1.4.3 Redes Neuronales Convolucionales (CNN)\n",
    "\n",
    "Las redes neuronales convolucionales pueden tener decenas o cientos de capas, y cada una de ellas aprende a detectar diferentes características de una imagen. Se aplican filtros a las imágenes de entrenamiento con distintas resoluciones, y la salida resultante de convolucionar cada imagen se emplea como entrada para la siguiente capa. Los filtros pueden comenzar como características muy simples, tales como brillo y bordes, e ir creciendo en complejidad hasta convertirse en características que definen el objeto de forma singular.\n",
    "\n",
    "Una CNN consta de una capa de entrada, una capa de salida y varias capas ocultas entre ambas.\n",
    "Estas capas realizan operaciones que modifican los datos, con el propósito de comprender sus características particulares.\n",
    "\n",
    "<center><img src=\"image12.png\" width=600> </center>\n",
    "\n",
    "- Capa de entrada: La capa de entrada recibe la imagen de entrada y puede aplicar algunas transformaciones iniciales, como redimensionar la imagen o normalizar los valores de píxeles.\n",
    "\n",
    "- Capas convolucionales: Las capas convolucionales son el componente principal de una CNN y se utilizan para extraer características de las imágenes. Cada capa convolucional aplica múltiples filtros (kernels) que se deslizan por la imagen y realizan operaciones de convolución para detectar características locales, como bordes, texturas o formas. Estas capas convolucionales generan mapas de características convolucionales, que capturan información relevante de la imagen a diferentes niveles de abstracción.\n",
    "\n",
    "- Capas de activación: Después de cada capa convolucional, se aplica una función de activación no lineal, como la función ReLU (Rectified Linear Unit), para introducir no linearidades en la red y permitir la representación de relaciones no lineales en los datos.\n",
    "\n",
    "- Capas de agrupación (Pooling): Las capas de agrupación se utilizan para reducir la dimensionalidad de los mapas de características y hacer que la red sea más robusta ante pequeñas variaciones en la posición de las características detectadas.\n",
    "La operación de agrupación toma una región de los mapas de características y aplica una función de agregación, como el máximo o el promedio, para obtener un único valor representativo de esa región.\n",
    "\n",
    "- Capas totalmente conectadas: Después de las capas convolucionales y de agrupación, se pueden agregar una o varias capas totalmente conectadas, similares a las de una red neuronal tradicional. Estas capas toman los mapas de características resultantes y los \"aplanan\" en un vector unidimensional, que luego se alimenta a través de capas densamente conectadas. Estas capas completamente conectadas aprenden a combinar y clasificar las características extraídas por las capas anteriores para producir las salidas deseadas, como etiquetas de clase en un problema de clasificación.\n",
    "\n",
    "- Capa de salida: La capa de salida generalmente consiste en una o varias neuronas que representan las clases o valores de salida deseados. En problemas de clasificación, se utiliza una función de activación softmax para obtener una distribución de probabilidades sobre las clases. En problemas de regresión, se puede utilizar una función de activación lineal o una función no lineal adecuada, según el rango de valores de salida requerido.\n",
    "\n",
    "\n",
    "Cabe mencionar que la estructura exacta de una red neuronal convolucional puede variar dependiendo de la arquitectura específica utilizada, como LeNet, AlexNet, VGGNet, ResNet, entre otras. Cada arquitectura puede tener una cantidad diferente de capas, así como también puede incluir capas adicionales o técnicas avanzadas, como la normalizació\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.      Esquema matemático de las redes neuronales\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Definición formal de red neuronal\n",
    "\n",
    "Para obtener una definición de red neuronal tenemos que hacer uso del concepto matemático de grafo. A través de este término, podemos definir una red neuronal de la siguiente forma:\n",
    "\n",
    "**Definición**\n",
    "Una red neuronal es un grafo dirigido con las siguientes propiedades:\n",
    "\n",
    "1. A cada nodo i se le asocia un variable de estado $x_i$.\n",
    "2. A cada conexión (i, j) de los nodos i y j se el asocia un peso $w_{ij} \\in \\mathbb{R}$.\n",
    "3. A cada nodo i se le asocia un umbral $\\theta_i$.\n",
    "4. Para cada nodo i se define una función $f_i(x_i, w_{ij}, \\theta_i)$, que depende de los pesos de sus conexiones, del umbral y de los estados de los nodos j a él conectados. Esta función proporciona el nuevo estado del nodo.\n",
    "\n",
    "\n",
    "Cuando trabajamos con redes neuronales el esquema matemático a seguir es el siguiente. Comenzamos explorando lo que sucede con una sola neurona.\n",
    "### 2.2 Suma ponderada\n",
    "Las señales de entrada $\\vec{x}=(x_1, x_2, \\ldots, x_n)$, la información que recibe nuestra neuronal artificial, son variables independientes. Los n-valores de entrada son multiplicados por sus respectivos pesos, es decir en la sinopsis el vector entrada es multiplicado por el vector peso, dando como resultado una combinación lineal de las entradas y los pesos, algo que denominamos suma ponderada.\n",
    "$$\\vec{x} \\cdot \\bf{\\vec{w}^T} = (x_1, x_2, \\ldots x_n) \\cdot \\begin{pmatrix}\n",
    "    w_1 \\\\\n",
    "    w_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    w_n \\\\\n",
    "\\end{pmatrix}\n",
    "= \\sum_{i=1}^n x_i w_i$$\n",
    "\n",
    "Además de las entradas y los pesos, una neurona puede tener un sesgo (bias) adicional. En el esquema matemático de una neurona, el bias se agrega como un término adicional en la suma ponderada de las entradas antes de aplicar la función de activación. El valor del bias se establece de manera aleatoria en un primer momento y se ajusta durante el proceso de entrenamiento de la red neuronal junto con los pesos sinápticos. Al ajustar el valor del bias, se puede lograr un mejor ajuste y rendimiento de la red neuronal en la tarea específica que está realizando. Enseguida agregamos el factor bias o sesgo $w_0$.\n",
    "$$w_0 + \\vec{x} \\cdot \\bf{\\vec{w}^T}\n",
    "= w_0 + \\sum_{i=1}^n x_i w_i$$\n",
    "\n",
    "### 2.3 Funciones de activación\n",
    "La suma ponderada se pasa a través de una función de activación, que introduce no linealidad en la salida de la neurona. Esta determina el rango y la forma de la salida de la neurona. La función de activación permite crear estructuras más complejas de neuronas secuenciales conectadas sin que \"colapsen\", ya que sin la función de activación, una red neuronal se reduciría a una combinación lineal de las entradas y los pesos, lo que limitaría su capacidad de aprendizaje y representación de datos complejos.\n",
    "Aplicamos la función de activación:\n",
    "$$f(w_0 + \\vec{x} \\cdot \\bf{\\vec{w}^T})$$\n",
    "\n",
    "Y por último dicho resultado se propaga a la salida. Dicho valor puede ser la nueva entrada de una neurona, formando así las redes neuronales, o bien puede ser el resultado final, nuestra variable respuesta.\n",
    "\n",
    "    \n",
    "Existen distintas funciones de activación, a continuación presente algunos ejemplos con casos de uso comunes:\n",
    "    <center><img src=\"Imagen3.png\" width=600> </center>\n",
    "    \n",
    "    \n",
    "- Función Sigmoide:  La función sigmoide se utiliza principalmente en la capa de salida para clasificación binaria. $$f(x) = \\sigma (x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Función tangente hiperbólica $\\tanh$: La función tangente hiperbólica es útil en capas ocultas de redes neuronales, especialmente en problemas de clasificación donde las salidas pueden tener tanto valores positivos como negativos.  $$f(x) = \\tanh(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}$$\n",
    "\n",
    "- Función ReLU: La función ReLU es ampliamente utilizada en las capas ocultas de las redes neuronales, especialmente en arquitecturas más profundas. Es menos propensa al problema de desvanecimiento de gradientes y puede acelerar el proceso de entrenamiento.\n",
    "$$f(x) = \\max(0,x)$$\n",
    "\n",
    " - Función Softmax: La función de activación softmax se utiliza comúnmente en la capa de salida de una red neuronal cuando se está abordando un problema de clasificación multiclase. La función softmax produce una distribución de probabilidades entre las clases, asignando un valor entre 0 y 1 a cada clase, de modo que la suma de todas las salidas sea igual a 1.\n",
    "    $$f(x_i)=\\frac{e^{x_i}}{\\sum_{j=1}^{n}e^{x_j}}$$\n",
    "\n",
    "### 2.4 Entrenamiento de la red neuronal (algoritmos)\n",
    "El objetivo del algoritmo de entrenamiento de redes neuronales es ajustar los pesos sinápticos y los sesgos de la red de manera que la red pueda aprender y generalizar a partir de los datos de entrenamiento. El algoritmo busca encontrar una configuración de pesos y sesgos que minimice la diferencia entre las salidas predichas por la red y las salidas objetivo deseadas.\n",
    "\n",
    "El proceso de entrenamiento implica presentar iterativamente los ejemplos de entrenamiento a la red neuronal, propagar hacia adelante las entradas a través de las capas de la red para calcular las salidas predichas y luego comparar esas salidas con las salidas objetivo. A partir de la diferencia entre las salidas predichas y las salidas objetivo, se calcula una función de pérdida o error que cuantifica qué tan bien está realizando la red en la tarea.\n",
    "\n",
    "El algoritmo de entrenamiento utiliza el error calculado para ajustar los pesos y sesgos en sentido contrario al gradiente de la función de pérdida. Esto se conoce como descenso de gradiente y se realiza mediante el algoritmo de backpropagation. El objetivo es encontrar una configuración de pesos y sesgos que minimice el error de manera gradual a medida que se presentan más ejemplos de entrenamiento.\n",
    "\n",
    "En resumen, el objetivo del algoritmo de entrenamiento de redes neuronales es optimizar los parámetros de la red para que pueda realizar predicciones precisas y generalizar a partir de los datos de entrenamiento, es decir, ser capaz de realizar predicciones precisas en datos no vistos anteriormente.\n",
    "\n",
    "### 2.5 Función de pérdida\n",
    "Es importante establecer cómo vamos a medir el desempeño de la red neuronal, para esto necesitamos definir cómo mediremos los errores. La función de pérdida es una parte fundamental cuando utilizamos modelos de redes neuronales porque determina el objetivo del algoritmo.\n",
    "$$Loss(\\hat{y}_{i}, y_{i})$$\n",
    "\n",
    "La \"loss function\" (función de pérdida) en las redes neuronales es una función que cuantifica el error entre las salidas predichas por la red y las salidas objetivo o etiquetas conocidas. El objetivo del entrenamiento es minimizar la función de pérdida promedio, es decir, reducir la discrepancia entre las salidas predichas y las salidas objetivo.\n",
    "\n",
    "$$AverageLoss\\Big (\\frac{1}{n} \\sum_{i=1}^n Loss( \\hat{y}_{i}, y_{i})\\Big)$$\n",
    "\n",
    "Existen diferentes funciones de pérdida, algunos ejemplos comunes son las siguientes:\n",
    "\n",
    "- Error cuadrado medio (MSE): Pone gran énfasis la magnitud promedio del error, independientemente de su dirección. Sin embargo, debido al cuadrado, las predicciones que están lejos de los valores reales son penalizadas en gran medida en comparación con las predicciones menos desviadas. Además, el MSE tiene propiedades matemáticas favorables que facilitan el cálculo de los gradientes. $$MSE = \\frac{ \\sum_{i=1}^n ( y_{i} - \\hat{y}_{i})^2}{n}$$\n",
    "\n",
    "- Error absoluto medio (MAE): El error absoluto medio (MAE, por sus siglas en inglés), por otro lado, se mide como el promedio de la suma de las diferencias absolutas entre las predicciones y las observaciones reales. Al igual que el error cuadrático medio (MSE), esto también mide la magnitud del error sin tener en cuenta su dirección. A diferencia del MSE, el MAE requiere herramientas más complicadas, como la programación lineal, para calcular los gradientes. Además, el MAE es más robusto ante valores atípicos ya que no utiliza el cuadrado $$MAE = \\frac{ \\sum_{i=1}^n | y_{i} - \\hat{y}_{i}|}{n}$$\n",
    "\n",
    "### 2.7 Forward propagation\n",
    "El proceso de propagación hacia adelante (forward propagation en inglés) en una red neuronal se basa en realizar una serie de cálculos matemáticos para propagar la información de entrada a través de las capas de la red y obtener una salida final. A continuación, se presenta un esquema matemático simplificado del proceso de propagación hacia adelante en una red neuronal de alimentación directa (feedforward) con una capa oculta:\n",
    "\n",
    "Asigna las entradas:\n",
    "\n",
    "$\\vec{x} = (x_1, x_2, x_3, ..., x_n)$ (vector de características de entrada)\n",
    "\n",
    "Calcula la salida de la primera capa oculta:\n",
    "$Z_1 = w_1 * \\vec{x} + b_11$\n",
    "\n",
    "$A_1 = f_1(Z_1)$\n",
    "donde:\n",
    "$W_1$ es la matriz de pesos de la capa oculta\n",
    "$b_1$ es el vector de sesgos de la capa oculta\n",
    "$f_1$ es la función de activación de la capa oculta\n",
    "Calcula la salida de la capa de salida:\n",
    "\n",
    "$Z_2 = W_2 * A_1 + b_2$\n",
    "\n",
    "$A2 = f2(Z2)$\n",
    "donde:\n",
    "W2 es la matriz de pesos de la capa de salida\n",
    "b2 es el vector de sesgos de la capa de salida\n",
    "f2 es la función de activación de la capa de salida\n",
    "La salida final de la red neuronal es A2, que representa las predicciones o salidas del modelo.\n",
    "\n",
    "El proceso de propagación hacia adelante en una red neuronal implica calcular la salida de cada capa a partir de las entradas y los pesos correspondientes, aplicar una función de activación a cada salida para introducir no linealidad, y repetir este proceso para cada capa hasta llegar a la capa de salida. La salida final de la red es el resultado de la última capa de activación.\n",
    "\n",
    "### 2.8 Backpropagation\n",
    "Backpropagation (retropropagación del error) es un algoritmo fundamental utilizado en el entrenamiento de redes neuronales para ajustar los pesos sinápticos de manera eficiente. Permite calcular el gradiente de la función de pérdida o error con respecto a los pesos de la red, lo que facilita la actualización de los pesos en la dirección que reduce el error de predicción.\n",
    "\n",
    "El proceso de backpropagation se realiza en dos fases principales: propagación hacia adelante (forward propagation) y retropropagación del error.\n",
    "\n",
    "Propagación hacia adelante (Forward Propagation):\n",
    "En esta fase, se toma un conjunto de datos de entrada y se propagan a través de la red neuronal capa por capa. Cada neurona realiza una suma ponderada de las entradas recibidas, aplica una función de activación no lineal y produce una salida que se propaga a la siguiente capa. Este proceso continúa hasta que se obtiene la salida final de la red.\n",
    "\n",
    "Retropropagación del error (Backpropagation):\n",
    "Después de obtener la salida de la red neuronal, se compara con las salidas deseadas utilizando una función de pérdida o error. A continuación, se calcula el gradiente de la función de pérdida con respecto a los pesos de la red.\n",
    "\n",
    "El cálculo del gradiente se realiza mediante la regla de la cadena (chain rule) de cálculo diferencial. El gradiente se calcula en sentido inverso, comenzando desde la capa de salida y retrocediendo hacia la capa de entrada. Para cada neurona, se calcula el gradiente del error con respecto a los pesos sinápticos y se actualizan dichos pesos en dirección opuesta al gradiente.\n",
    "\n",
    "El objetivo del algoritmo de backpropagation es minimizar la función de pérdida ajustando los pesos de manera iterativa. Esto se logra actualizando los pesos utilizando un algoritmo de optimización, como el descenso del gradiente, que modifica los pesos en función de la magnitud del gradiente y una tasa de aprendizaje.\n",
    "\n",
    "La retropropagación del error es esencial para el entrenamiento de redes neuronales profundas, ya que permite el ajuste eficiente de los pesos en todas las capas de la red. Al propagar el error desde la capa de salida hasta la capa de entrada, la red puede aprender a realizar predicciones más precisas y ajustarse a los patrones de los datos de entrenamiento.\n",
    "\n",
    "\n",
    "### 2.9 Descenso de gradientes\n",
    "Antes de sumergirnos en el descenso de gradiente, puede ser útil revisar algunos conceptos de la regresión lineal. Puede recordar la siguiente fórmula para la pendiente de una línea, que es y = mx + b, donde m representa la pendiente y b  es la intersección en el eje y.\n",
    "\n",
    "También puede recordar trazar un diagrama de dispersión en estadísticas y encontrar la línea de mejor ajuste, lo que requirió calcular el error entre la salida real y la salida predicha (y-hat) usando la fórmula del error cuadrático medio. El algoritmo de descenso de gradiente se comporta de manera similar, pero se basa en una función convexa.\n",
    "\n",
    "El punto de partida es solo un punto arbitrario para que podamos evaluar el rendimiento. Desde ese punto de partida, encontraremos la derivada (o pendiente), y desde allí, podemos usar una recta tangente para observar la inclinación de la pendiente. La pendiente informará las actualizaciones de los parámetros, es decir, los pesos y el sesgo. La pendiente en el punto de partida será más pronunciada, pero a medida que se generen nuevos parámetros, la pendiente debe reducirse gradualmente hasta alcanzar el punto más bajo de la curva, conocido como punto de convergencia.   \n",
    "\n",
    "De manera similar a encontrar la línea de mejor ajuste en la regresión lineal, el objetivo del descenso de gradiente es minimizar la función de costo, o el error entre y pronosticada y real. Para hacer esto, se necesitan dos puntos de datos: una dirección y una tasa de aprendizaje. Estos factores determinan los cálculos de derivadas parciales de iteraciones futuras, lo que le permite llegar gradualmente al mínimo local o global (es decir, punto de convergencia).\n",
    "\n",
    "Tasa de aprendizaje (también conocida como tamaño de paso o alfa)  es el tamaño de los pasos que se dan para alcanzar el mínimo. Suele ser un valor pequeño y se evalúa y actualiza en función del comportamiento de la función de costos. Elevado  Las tasas de aprendizaje dan como resultado pasos más grandes, pero se corre el riesgo de sobrepasar el mínimo. Por el contrario, una tasa de aprendizaje baja  tiene tamaños de paso pequeños. Si bien tiene la ventaja de una mayor precisión, el número de iteraciones compromete la eficiencia general, ya que esto requiere más tiempo y cálculos para alcanzar el mínimo.\n",
    "\n",
    "La función de costo (o pérdida)  mide la diferencia, o error, entre la y real y la y pronosticada en su posición actual. Esto mejora la eficacia del modelo de machine learning , proporcionando feedback al modelo para que pueda ajustar los parámetros para minimizar el error y encontrar el mínimo local o global. Repite continuamente, moviéndose a lo largo de la dirección de descenso más pronunciado (o el gradiente negativo) hasta que la función de costo está cerca o en cero. En este punto, el modelo dejará de aprender. Además, si bien los términos función de costo y función de pérdida se consideran sinónimos, existe una ligera diferencia entre ellos. Vale la pena señalar que una función de pérdida se refiere al error de un ejemplo de entrenamiento, mientras que una función de costo calcula el error promedio en todo un conjunto de entrenamiento.\n",
    "\n",
    "#### 2.9.1  Tipos de descenso de gradiente\n",
    "Hay tres tipos de  algoritmos de aprendizaje de descenso de gradiente: descenso de gradiente por lotes, descenso de gradiente estocástico y descenso de gradiente por mini lotes.\n",
    "\n",
    "**Descenso de gradiente por lote** \n",
    " \n",
    "El descenso de gradiente por Lote  suma el error para cada punto en un conjunto de entrenamiento, actualizando el modelo solo después de que todos los ejemplos de entrenamiento  han sido evaluados. Este proceso se conoce como época de entrenamiento.\n",
    "\n",
    "Si bien este procesamiento por lotes proporciona eficiencia de cálculo, aún puede tener un tiempo de procesamiento prolongado para grandes conjuntos de datos de entrenamiento, ya que aún necesita almacenar todos los datos en la memoria. El descenso del gradiente por lotes también suele producir un gradiente de error estable y una convergencia, pero a veces ese punto de convergencia no es el ideal, encontrando el mínimo local versus el global.\n",
    "\n",
    "**Descenso de gradiente estocástico**\n",
    " \n",
    "El descenso de gradiente estocástico (SGD) ejecuta una época de entrenamiento para cada ejemplo dentro del conjunto de datos y actualiza cada  parámetro del ejemplo de entrenamiento, uno a la vez. Dado que solo necesita guardar un ejemplo de entrenamiento, es más fácil almacenarlos en la memoria. Si bien estas actualizaciones frecuentes pueden ofrecer más detalles y velocidad, pueden resultar en pérdidas en la eficiencia computacional en comparación con el descenso de gradiente de lote . Sus actualizaciones frecuentes pueden resultar en gradientes ruidosos, pero esto también puede ser útil para escapar del mínimo local y encontrar el global.\n",
    "\n",
    "**Descenso de gradiente de mini-lote**\n",
    "\n",
    "El descenso de gradiente de Mini-lote combina conceptos tanto del descenso de gradiente por lotes como del descenso de gradiente estocástico. Divide el conjunto de datos de entrenamiento en pequeños tamaños de lote  y realiza actualizaciones en cada uno de esos lotes. Este enfoque logra un equilibrio entre la eficiencia computacional del lote de descenso de gradiente y la velocidad del  descenso de gradiente estocástico.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Problema propuesto y esquema a seguir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.   Bibliografía"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.youtube.com/watch?v=eNIqz_noix8\n",
    "\n",
    "https://www.youtube.com/watch?v=M5QHwkkHgAA&t=3s\n",
    "\n",
    "https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e\n",
    "\n",
    "https://rstudio-pubs-static.s3.amazonaws.com/599210_4306c5d3d6a34a6c829566ca11b7e27a.html#1\n",
    "\n",
    "https://medium.com/@draj0718/convolutional-neural-networks-cnn-architectures-explained-716fb197b243\n",
    "\n",
    "https://www.ibm.com/mx-es/topics/gradient-descent\n",
    "\n",
    "https://www.ibm.com/mx-es/topics/neural-networks\n",
    "\n",
    "\n",
    "\n",
    "https://www.aprendemachinelearning.com/como-funcionan-las-convolutional-neural-networks-vision-por-ordenador/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
